{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lane Following Problem\n",
    "===========================\n",
    "\n",
    "The dynamics model of an omnidirectional vehicle with no friction is defined by the following equation:\n",
    "\n",
    "$$\n",
    "\\dot{p}^x(t) = (v_k + \\dot{v}_k(t-T_s k))cos(\\theta_k + \\theta_k(t - T_sk))\n",
    "$$\n",
    "$$\n",
    "\\dot{p}^y(t) = (v_k + \\dot{v}_k(t - T_s k))sin(\\theta_k + \\theta_k(t - T_s k))\n",
    "$$\n",
    "\n",
    "iLQR is applied to a vehicle in order to control them to follow a reference trajectory at a terminal velocity of $10 m/s$.\n",
    "\n",
    "The state vector $\\textbf{x}$ is defined as follows:\n",
    "$$\\begin{equation*}\n",
    "\\textbf{x} = \\begin{bmatrix}\n",
    "    p^x & p^y & v & \\theta\n",
    "    \\end{bmatrix}^T\n",
    "\\end{equation*}$$\n",
    "\n",
    "The action vector $\\textbf{u}$ is defined as follows:\n",
    "$$\\begin{equation*}\n",
    "\\textbf{u} = \\begin{bmatrix}\n",
    "   \\dot{v} & \\delta\n",
    "    \\end{bmatrix}^T\n",
    "\\end{equation*}$$\n",
    "\n",
    "**Note**: That since this dynamics model is nonlinear, this problem can be solved\n",
    "more efficiently with a simple Linear Quadratic Regulator (LQR) instead. This\n",
    "example is just used to demonstrate how to setup an auto-differentiated\n",
    "dynamics model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import random\n",
    "import ilqr\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ilqr import iLQR\n",
    "from ilqr.cost import PathQRCost\n",
    "from ilqr.examples.car import CarDynamics, CarCost\n",
    "\n",
    "from bc import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_iteration(iteration_count, xs, us, J_opt, accepted, converged):\n",
    "    J_hist.append(J_opt)\n",
    "    info = \"converged\" if converged else (\"accepted\" if accepted else \"failed\")\n",
    "    final_state = xs[-1]\n",
    "    final_control = us[-1]\n",
    "    if iteration_count % 60 == 0:\n",
    "        print(\"iteration\", iteration_count, info, J_opt, final_state, final_control)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.05\n",
    "wheel_diameter = 1.0\n",
    "dynamics = CarDynamics(dt, l=wheel_diameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instantaneous cost function $l(\\textbf{x}_t, \\textbf{u}_t)$ is defined as follows:\n",
    "\n",
    "$$\n",
    "l(\\textbf{x}_t, \\textbf{u}_t) = \\textbf{x}_t^T Q \\textbf{x}_t + \\textbf{u}_t^T R \\textbf{u}_t\n",
    "$$\n",
    "\n",
    "where $Q$ is the state error and $R$ is the control error.\n",
    "\n",
    "In order to approach the two vehicles to each other, $Q$ is set up to penalize differences in positions as $||\\textbf{x}_0 - \\textbf{x}_1||^2$ while penalizing non-zero velocities.\n",
    "\n",
    "The following code generates the lane and boundaries. There are 150 way points along the reference trajectory. The boundary is +-3 vertically away from the reference trajecotry.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lane(posx):\n",
    "    ts = [80, 90, 150]\n",
    "    rate = 6.0\n",
    "    height = 6.0\n",
    "    if posx <= ts[0]:\n",
    "        return -height * np.exp((posx - ts[0])/(1 * rate)), np.arctan(-height * np.exp((posx - ts[0])/(1 * rate)/(1 * rate)))\n",
    "    elif posx > ts[0] and posx <= ts[1]:\n",
    "        return -height * np.exp(ts[0] - ts[0]), np.arctan(0)\n",
    "    elif posx > ts[1]:\n",
    "        return -height * np.exp((ts[1] - posx)/(1 * rate)), np.arctan(+ height * np.exp((ts[1] - posx)/(1 * rate)))\n",
    "\n",
    "'''\n",
    "\n",
    "def nominal(posx):\n",
    "    ts = [80, 90, 150]\n",
    "    rate = 6.0\n",
    "    height = 6.0\n",
    "    if posx <= ts[0]:\n",
    "        return -height * np.exp((posx - ts[0])/(1 * rate)), np.arctan(-height * np.exp((posx - ts[0])/(1 * rate)/(1 * rate)))\n",
    "    elif posx > ts[0] and posx <= ts[1]:\n",
    "        return -height * np.exp(ts[0] - ts[0]), np.arctan(0)\n",
    "    elif posx > ts[1]:\n",
    "        return -height * np.exp((ts[1] - posx)/(1 * rate)), np.arctan(+ height * np.exp((ts[1] - posx)/(1 * rate)))\n",
    "\n",
    "\n",
    "def lane(posx):\n",
    "    ts = [30, 60, 90, 120]\n",
    "    rate = 6.0\n",
    "    height = 6.0\n",
    "    if posx <= ts[0]:\n",
    "        return -height * np.exp((posx - ts[0])/rate), np.arctan(-height * np.exp((posx - ts[0])/rate)/rate)\n",
    "    elif posx > ts[0] and posx <= ts[1]:\n",
    "        return -height * np.exp(ts[0] - ts[0]), np.arctan(0)\n",
    "    elif posx > ts[1] and posx <= ts[3]:\n",
    "        return -height * np.exp((ts[1] - posx)/(2 * rate)), np.arctan(+ height * np.exp((ts[1] - posx)/(2 * rate)))\n",
    "    #elif posx > ts[2] and posx <= ts[3]:\n",
    "    #    return -height * np.exp((posx - ts[2])/rate), np.arctan(-height * np.exp((posx - ts[2])/rate)/rate)\n",
    "    elif posx > ts[3]:\n",
    "        return -height * np.exp((posx - ts[3])/(2 * rate)), np.arctan(+ height * np.exp((ts[3] - posx)/(2 * rate)))\n",
    "    \n",
    "def nominal(posx):\n",
    "    ts = [30, 60, 90, 120]\n",
    "    rate = 6.0\n",
    "    height = 6.0\n",
    "    if posx <= ts[0]:\n",
    "        return -height * np.exp((posx - ts[0])/rate), np.arctan(-height * np.exp((posx - ts[0])/rate)/rate)\n",
    "    elif posx > ts[0] and posx <= ts[1]:\n",
    "        return -height * np.exp(ts[0] - ts[0]), np.arctan(0)\n",
    "    elif posx > ts[1] and posx <= ts[3]:\n",
    "        return -height * np.exp((ts[1] - posx)/(2 * rate)), np.arctan(+ height * np.exp((ts[1] - posx)/(2 * rate)))\n",
    "    #elif posx > ts[2] and posx <= ts[3]:\n",
    "    #    return -height * np.exp((posx - ts[2])/rate), np.arctan(-height * np.exp((posx - ts[2])/rate)/rate)\n",
    "    elif posx > ts[3]:\n",
    "        return -height * np.exp((posx - ts[3])/(2 * rate)), np.arctan(+ height * np.exp((posx - ts[3])/(2 * rate)))\n",
    "'''\n",
    "\n",
    "def barrier_u(posx):\n",
    "    ts = [80, 90, 150]\n",
    "    if posx <= ts[0]:\n",
    "        return + 1 + posx, + 2 + lane(posx)[0], lane(posx)[1]\n",
    "    elif posx > ts[0] and posx <= ts[1]:\n",
    "        return + 1 + posx, + 2 + lane(posx)[0], lane(posx)[1]\n",
    "    elif posx > ts[1]:\n",
    "        return + 1 + posx, + 2 + lane(posx)[0], lane(posx)[1]\n",
    "                                                                      \n",
    "def barrier_l(posx):\n",
    "    ts = [80, 90, 150]\n",
    "    if posx <= ts[0]:\n",
    "        return - 1 + posx, -2 + lane(posx)[0], lane(posx)[1]\n",
    "    elif posx > ts[0] and posx <= ts[1]:\n",
    "        return - 1 + posx, -2 + lane(posx)[0], lane(posx)[1]\n",
    "    elif posx > ts[1]:\n",
    "        return - 1 + posx, -2 + lane(posx)[0], lane(posx)[1]\n",
    "    \n",
    "def nominal(posx):\n",
    "    return (barrier_u(posx)[1] + barrier_l(posx)[1]) * 0.5, (barrier_u(posx)[2] + barrier_l(posx)[2]) * 0.5\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xl8VNX9//HXyb6QlbAnI0nYEkEIBISAVoFY3AX9ule0rbjUVv3qr2rpZqvW2kXrt7h1caWKVRRXKuBSJYAsYU1YkgBZCBCyQkjCJHN+f9wZyDLZZ+ZOJp/n4zGPYe69c++HgXnPmTPn3qO01gghhPAdfmYXIIQQwrUk2IUQwsdIsAshhI+RYBdCCB8jwS6EED5Ggl0IIXyMBLsQQvgYCXYhhPAxEuxCCOFjAsw4aFxcnB45cqQZhxZCiD5r8+bNx7TWgzrbzpRgHzlyJJs2bTLj0EII0WcppQ52ZTvpihFCCB8jwS6EED5Ggl0IIXyMBLsQQvgYCXYhhPAxvQ52pVSCUuoLpVSuUmqXUupeVxQmhBCiZ1wx3LEReEBrvUUpFQFsVkqt0lrnuGDfQgghuqnXwa61LgVK7X8+rpTKBUYALg/2j/Z+xLcl355+rFDGvVJtljVf7mxZd57vyWN19vyeHEuhCPALOH0L9A807v0C213meBwaEEpYYBjhQeGEBoS2OI4Q7qC1pqGpgTprHSetJzlpPUldYx3WJitWm5VGW+Ppm7Wp1eNm65tsTWg0WusW9zZta7NMa/vyLm7vrOY2y5xsB3DzOTczKnaUy1+35lx6gpJSaiSQBmxwsm4RsAjAYrH0aP8r81by3MbngPZfNOFeYYFhhAeGEx4UTlhgGFHBUQwMG8jAUPvN/uchA4ZgibJgibIwMHSgfCD0UzUNNZTUlFBcU0zJ8RJKj5dSUVdBZX3l6fvKukqq6quotdaeDnNffn9Pj5/u9mBXrprMWik1APgKeFxrvbyjbdPT07U7zjxt/ndx/Mdwtqz5cmfLerqtu5/f02PZtI0mW1ObFk3z1o6z5Vab9fQbrdZaS+2pWmqttS0eV9VXUV5XTvnJcirqKqi11tJaWGAYligLidGJjB88nrMHnc34weNJHZRKaGBom+1F36K1Zl/FPrJLs9l9bDe7y3ez59ge8iryOH7qeJvtQwJCiAmJITY0lpjQGGJCYogOiWZA0IDT3xAdt9BA43FoQChB/kFtvmGeftzq26e/8sffzx+FQil1+t5P+bVZprAvb7Wso+2dNVSaf4M+vczFDRql1GatdXpn27mkxa6UCgTeBZZ2Furu5LTrQhqKHlXfWE9FXQWlx0sprC48c6spZF/5Pj7f/zkNTQ0ABPgFMGnoJDLiMzjvrPOYmzSX6JBok/8GojPWJitri9by5YEvWV+8nm9LvqWyvhIw3ncjo0cyNm4ssyyzSIhMYETkCOIj4xkRMYJhEcMICwwz+W/g+3rdYldGmr4KVGit7+vKc9zVYhfer9HWSH5FPrvKdrH50GayirP4tuRbTlpP4q/8mWmZyRVjruCGCTcwPGK42eUKu5PWk7y/+32W5y5nVcEqahpq8FN+jB88nnNHnMu5I84lfXg6YwaOkW9hbtTVFrsrgn0W8DWwA7DZF/9Ma/1Je8+RYBfNWZusfFvyLR/v+5iP933M9iPb8VN+fDf5u9w26Tbmp8wnwM+U69X1extLNvLS5pdYtmsZx08dZ3jEcC4dfSmXjL6E2YmziQyONLvEfsVjwd4TEuyiI3vL9/Lattd4ddurFNcUMyp2FA/PfJjvTfweQf5BZpfn87TWfHngS5745glWF6wmPDCc/zn7f1g4cSHnn3U+fkrOazSLBLvo85psTXyw5wMe//pxNpduxhJl4am5T3Ht2dfKKBs32XZ4Gz9Z+RP+e/C/DB0wlAdmPMAdU+4gIjjC7NIEXQ92+egVXsvfz5/5KfPZePtGPr3pU2JDY7n+3euZ89ocCioLzC7Pp5y0nuTeT+9l8kuTySnL4a8X/5X99+7nwYwHJdT7IAl24fWUUswbNY9Nt2/iuUueY0vpFia+MJFXtr7i9MQQ0T2bDm0i7cU0nv32We5Kv4u99+zlR9N+REhAiNmliR6SYBd9hr+fP3dNvYvtd21nyrAp3LbiNu746A5ONZ0yu7Q+69WtrzLznzOps9ax5pY1/PWSvxITGmN2WaKXJNhFn2OJsrDmljX8bNbP+NuWv5H5eiaVdZVml9WnaK356aqfcuuKW5llmUX2HdnMTpxtdlnCRSTYRZ/k7+fP43MeZ+mCpawvXs+c1+ZQfrLc7LL6BJu2cdfHd/GHrD9wV/pdrLxpJQPDBppdlnAhCXbRp9044UZWXL+CnLIcZr82W8K9E1prFn24iBc3v8jDMx9mySVLCPQPNLss4WIS7KLPmzdqHh/e8CF7ju3hqmVXUd9Yb3ZJXutXX/6Kf2T/g8XnLeaJOU/IsFEfJcEufEJmciavXvUq3xR+w/dXfB+btnX+pH7m5eyX+e1/f8v3J32f3174Wwl1HybnaQufcd346yioLOBnn/+MiUMm8tCsh8wuyWtsOrSJOz66g8ykTF647AUJdR8nLXbhUx6e9TDXpF7Dz7/4ORuK20wL0C/VNNRw/TvXM2TAEN68+k3pU+8HJNiFT1FK8dJlLzE8Yjg3vHsD1fXVZpdkurs+vosDVQd48+o3ZfRLPyHBLnxOTGgMb179JgerD/Lw6ofNLsdUH+z5gH/t+Be//M4vmWWZZXY5wkMk2IVPykjI4CfTfsKLm1/st10yJ06d4J5P7mH84PE8MusRs8sRHiTBLnzWby78DcMihnHnx3fSaGs0uxyP+9UXv6KopogXL3tR+tX7GQl24bMigiP4y7y/sPXwVl7c9KLZ5XjU3vK9/GXDX1g0eREZCRlmlyM8TIJd+LSrU67m/LPO57GvH+Ok9aTZ5XjML774BSEBIfx29m/NLkWYQIJd+DSlFI/PfpzDJw7z12//anY5HrGldAtv73qb+6ffz+DwwWaXI0wgwS583izLLC4edTFPfvNkvxj+uPjzxcSGxvJgxoNmlyJMIsEu+oXHZj9GZX0lz2541uxS3Grzoc2szFvJQzMfIiokyuxyhEkk2EW/MHnYZOaNmseSjUtoaGwwuxy3+fP6PxMRFMGd6XeaXYowkQS76Dfun34/R2qP8NbOt8wuxS2Kqot4e9fb3D75diKDI80uR5hIgl30G5lJmZw96GyeXv+0T86V+n/f/h82beMn5/7E7FKEySTYRb+hlOK+6fex7cg2vjzwpdnluFTtqVpe2vwS16Rew1nRZ5ldjjCZBLvoV24+52ZiQ2N5cbNvnbD0bu67VDdUc8/Ue8wuRXgBCXbRr4QEhHDj+Bt5f/f7VNVXmV2Oy7y89WVGxY6SC30JQIJd9EMLJy2koamBZTuXmV2KS+yv3M+XB77k1om3ygQaApBgF/3QlGFTOHvQ2byy7RWzS3GJV7e9ikJxy8RbzC5FeAkJdtHvKKVYOHEh64vXs+fYHrPL6RWbtvHqtleZmzSXhKgEs8sRXkKCXfRLN59zM37Kj9e3v252Kb2yvng9B6oOsHDiQrNLEV7EJcGulJqnlNqjlMpTSvXvKWtEnzAsYhjnn3U+7+1+z+xSemV57nKC/IO4fOzlZpcivEivg10p5Q8sAS4GUoEblFKpvd2vEO42f9x8cspy2Fu+1+xSekRrzXu732Nu0lw501S04IoW+zQgT2tdoLU+BbwFXOmC/QrhVleNuwqA93L7Zqt9+5HtFFQWMH/cfLNLEV4mwAX7GAEUNXtcDJzrgv22ce+98MILZx47RnY1H+HVnT/74vPaWxYQcOYWGNjy3tkyx31oKISFQXi4cWv956goGDjwzC2wD83AZomyMGXYFN7b/R4PzXrI7HK6bXnucvyUH1eMvcLsUrqlqQmqqqCiAiorjVtVFdTWQl0dnDxp3Fr/2Wo1bo2NZ24dPW5qAq3b3my23i9vrruPP/gALrrI9a9rc64IdmcDZ9tciEMptQhYBGCxWHp0oNmzjTCBMy9W8xetO3/25ue5+hg2m/GfvPl//Ob3DQ3tr6urM95wJ7s4+VBEhBHwQ4eCxXLmdtZZkJgIY8dCUFDX9uUJ88fN5+df/JxDxw8xPGK42eV0y/LdyznPcp5XTaZhs0FxMezZA3l5xp9LSs7cl5ZCdRcviR8cfKZhERpq/L9p3RAJCDC2GzCg5Tp/f+OmVMubn1/bZT1Z3vp0ge48PssDV3xwRbAXA83HWcUDh1pvpLV+CXgJID09vUdXYLrySuMmPE/rliFfW2vcqqqgvNxofZWXn7mVlkJ2NqxYYXxwOAQEwOjRMH48nHMOZGTAtGnGG9MM81OMYF+xewV3Tb3LnCJ6IL8in51Hd/LMd58xrYbGRti1CzZsMG7Z2UagN28E+PvDsGEQHw9nnw1z5xof/DExEBtr3MfEQHS08X+geZD7+5v2V+vzXBHsG4HRSqlEoAS4HrjRBfsVXkQp4w3n+MbUVVpDWRkUFsK+fUYQ7NxphMA77xjr/fxg8mS4+GK45BKYOtVzb+qUuBSSY5L5NO/TPhXsn+V/BsAloy/x6HHz8uDTT+GTT+Drr40Pd4C4OEhPhwsuML6VjR1rfIAPHSoBbYZeB7vWulEpdQ/wH8Af+KfWelevKxM+QSkYPNi4pae3XFdVBevXQ1YWfP45PP44/Pa3MGQI3HQT3HorTJjg7voUmUmZLN2xFGuTlUD/vvEjwaqCVZwVdRajYke5/ViHD8PSpfDqq7Bjh7FszBi47TaYMQPOPReSktp2PwjzuGQcu9b6E631GK11stb6cVfsU/i+6GiYNw9+8xv45hs4etQIkIwM+L//M7pq0tPh7beN3wjcZW7SXI6fOs63Jd+67yAu1Ghr5PP9n5OZlOnWa8Ns3gzXXGN0ozz4oNE98swzxjevPXuMf6Mbb4TkZAl1byNnngqvMXCgERTLl8OhQ/Dss3DiBFx3ndE/+9pr7gn42YmzUShWFaxy/c7dYGPJRqobqslMznTL/tetMz5w09Nh9Wp44AHIzTX60e+9F0a5/0uC6CUJduGV4uLgxz82+uSXLTNGPixcCNOnGwHjSjGhMaQPT2d1wWrX7thNVhWsQqGYkzjHpfs9dAi+9z3jG1N2Njz5pPHbyO9/D+PGufRQws0k2IVX8/eHa6+FrVuNbppDh4xwf/DBlqNteiszKZP1xeupaahx3U7dZFXBKqYMn8LAsIEu2+ebbxrfit5+GxYvhoICeOghiJQTWvskCXbRJyhldNPs3g133gl/+pMxTDIvzzX7n5s0lybdxFcHvnLNDt2kpqGGdUXryExyTTfMyZNGK/3GGyElxRix9Nhjxgloou+SYBd9SkQEPP88fPSRccLLtGnGiJreykjIIDQg1Ou7Y7KKsmjSTcxOnN3rfRUVwXnnGd+EHn0U/vtfY4ii6Psk2EWfdOml8O23xskvF11kdCX0RnBAMNPjp5NVnOWaAt0kqygLP+XH9PjpvdrPnj1Gl9a+fcYp7r/8pXHymPANEuyiz0pKMkZwnHce3HwzvPFG7/aXkZBBdmk2tadqXVOgG6wtWsvEIRMZENTzU3V37oTvfMc4c3TtWrjsMhcWKLyCBLvo0yIj4eOP4cIL4ZZbjB//eiojIYMm3cSmQ5tcV6ALNdoa2VC8gZkJM3u8j4ICmDPHONv3q6/cfwKYMIcEu+jzwsLgww+NYXq33GKcydoTju6NrCLv7I7ZfmQ7tdZaZlp6FuwVFcYlG6xW43cJGcLouyTYhU8IDYX334eEBONCcfv3d38fsaGxpMSleG0/u+MDJyMho9vPbWyEBQuM12XFCgl1XyfBLnxGXJxxcSqrFa6/3rjvroyEDLKKstCtL6LtBdYWrSU+Mh5LVPcve/2rXxldL//4h/GbhPBtEuzCp4weDX/7mzFi5he/6P7zMxIyqKir8Mrp8rKKsnrUv756Nfzud/CDHxg/MgvfJ8EufM7//A8sWmScCv/FF9177oz4GQCsK17nhsp6rrimmMLqwm53w1RVGScgjRsHf/mLm4oTXkeCXfikp582LlZ1xx1QX9/1542NG0tMSIzX/YC6sWQjAOeO6N6sk488Ylw184035GzS/kSCXfiksDBYssQ4Aeepp7r+PD/lx5ThU9hSusV9xfVA9uFs/JU/5ww5p8vPWbfOmCP43nuNiUxE/yHBLnzWRRcZl/x94onuXVMmbWgaO47uwNrUg19f3WRL6RZSBqUQGhjape0bG41vKwkJxvXuRf8iwS582tNPG6fKL17c9eekDU3jVNMpco/luq+wbtpSuoXJw7re7H79dWO2oz//2bz5ZIV5JNiFTxs2DO6/3zgjNTu7a89JG5YGQHZpF5/gZodPHKb0RClpQ9O6tH1DA/z618bcsVdf7d7ahHeSYBc+74EHICYGfv7zrm0/OnY0YYFhZB/2jmB3fMB0tcX+wgvGBBlPPCFT1vVXEuzC50VHG5NGfPKJcdGrzvj7+TNxyETvCXZ7HZOGTup025MnjUnBZ8+GuXPdXZnwVhLsol+45x7jzNTf/75r26cNTWPr4a3YtM29hXXBltItjIodRWRw59MZvfYalJUZXTGi/5JgF/1CeDjcdZcxQce+fZ1vnzYsjZqGGvZX9uCiMy62pXRLl/rXbTbjx+KpU2HWLA8UJryWBLvoN+6+GwIDu3YGpiNIzR7PXllXyf6q/V3qX//kE9i7F/73f6Vvvb+TYBf9xtChcMMN8PLLUFnZ8bbjB48nwC/A9H72bUe2AXSpxf6nPxnj1mUkjJBgF/3K/fcbPzD+858dbxccEExKXMrpYDVLTlkOYHzQdLhdDnz5Jfz4x8a3EtG/SbCLfmXiRGOuz5dfhs6uzJs6KJXcMnNPUsopyyEyOJLhEcM73O7ll40TsW691TN1Ce8mwS76nVtvhV27YPPmjrdLiUvhQNUB6qx1HqnLmZyyHFIHpaI66DS3Wo0zTS+7DAYN8mBxwmtJsIt+57rrIDgYXnml4+1SB6Wi0ewp3+ORupzJKcshNS61w23+8x84cgRuu81DRQmvJ8Eu+p3oaLjqKnjzTeP0+/akDEoBzvRze1r5yXKO1B45XUd7Xn4ZBg+Giy/2UGHC60mwi37p1luNyZ0//LD9bUbHjsZf+ZvWz+64CFnqoPZb7I6/w803y4+m4gwJdtEvZWbCkCHGxcHaExwQTHJsMjnHzGmxO74pdBTsH3xg9LHfcIOnqhJ9Qa+CXSn1B6XUbqXUdqXUe0qpaFcVJoQ7+fvDlVfCp592PMOSmSNjcstyCQsM63Dy6uXLwWKBKVM8WJjwer1tsa8CxmutzwH2Ao/0viQhPGP+fDhxwpjsuT0pcSnsq9hnyqQbOcdySIlLwU85f5ueOAGffQYLFsiZpqKlgN48WWv9WbOH64FreldOxz7f/znbj2w//Vhh/G9uPhTMsawry7uzbV85XnvLAvwCTt8C/QKNe//Adpc5HocGhhIWGEaAX6/+q3il2bMhMhLef98YKuhMSlwKjbZG8iryOv0R09VyynK4cOSF7a7/9FPjx9/58z1YlAdpralvrOek9SR1jXVYm6xYbVYabY002hqxNjX7s5PlTboJrTUa7fTepm3trtPY17ezrnWdLR53sv7KcVcyMnqkW14zB1e+W78PLGtvpVJqEbAIwGJp/6tlR97NeZfnNj3Xo+eK3gnyDyI8MJywwDDCg8JP/zkqJIqBoQONW9iZ+6EDhmKJsjAiYgSB/t75q15QEFx6qdFP3dRkdM+05ujfzinL8Wiw1zTUUFxT3GH/+vLlxrj1mTM9Vla32bSNstoyimuKKTleQunxUirqKqisrzx9X1lXSVV9FbXWWuqsdZy0njwd5r5obNxY84NdKbUaGOpk1WKt9Qr7NouBRmBpe/vRWr8EvASQnp7eyTl/zv3hoj/w+JzHHfsz7pt9Ojb/ZOxseXe29fTxXF2bTdto0k0tWjOOFo6zVk/zbRxvtFprLbWnaqm11rZ4XHq8lJ1Hd1J+spxaay2tKRTDI4ZjibKQGJPI+EHjOXvw2YwfPJ6R0SPb7WbwlPnzjWGPa9fC+ee3XT8ubhyAx6fJc/TrtxfsDQ3w8cdw/fXOP5A8ray2jK2Ht7L72G52H9vNnvI95FXkcej4Iay2tt1Ywf7BxIbGEhMaQ0xIDMMjhjMgaIDxDTEgjLBA4+b4xhgaEEqQf1C73zRbLw/wC8Bf+aOUQqHa3Pspv3bXKWVf3846x31zzb9JAx2uHxDk/rkKOw12rXWHl+tXSi0ELgPm6NbfOVzM8Y8tvFNDYwMVdRWU15VTeryUwupC41Zj3H998Gv+teNfp7ePCIpgevx0ZibM5LyzzmOWZRZB/kEerfnii42TlVascB7s4UHhnBV1lsfHsu8t3wvAmIFjnK7/+ms4ftz4AdjTtNZsP7KdLw98yYaSDawvXs/+qjOXN44KjmJs3FhmWWaREJnAiMgRxEfGMyJiBMMihjEwdGCXJ+UWPdOrrhil1DzgIeA7WuuTrilJ9FXBAcEMixjGsIhh7V60qrq+mpyyHHaV7WLzoc1kFWfx6FePotEMCBrA3KS5XDHmCq5OvbpLE0v01oABcN55sGpV+9uMGTiGvIo8t9fSXF5FHgpFYnSi0/WrVhnj1i+4wDP1NNoaWZW/iuW5y/k071NKjpcAEB8Zz7kjzuXuqXeTPjydlLgUBocP7vASCML9etvH/lcgGFhl/4dcr7W+s9dVCZ8VFRLFjIQZzEiYwQ8n/xAw+pO/OvAVn+z7hI/3fcz7u9/nR5/8iAUpC7ht0m3MTpzt1qCYOxcefhgOHzYu7dtackwyy3a1+/ORW+RX5mOJshAcEOx0/apVkJFhTCDiTnvL9/L3LX/n9e2vc/jEYSKDI7ko+SIuHnUxFyVfRHxkvHsLED3S21Exo1xViOi/IoMjuXzs5Vw+9nK01mw8tJFXtr7CmzvfZOmOpUwZNoXF5y3mynFXuqVPPjPTCPY1a+Cmm9quT45NPv0jX0xojMuP70xeRR7JsclO1x09CtnZ8Nhj7jv+1sNb+d03v+Pfu/6Nv58/l4y+hIUTF3Lp6Evb/bAR3kPOPBVeRSnFtBHTeO7S5yh9oJS/Xf43quqrWPD2Aia+MJFV+R30mfTQpEkQG9t+d0xyjBGw+ZX5Lj92e/Ir8xkV47zdtGaNcZ+Z6frjFlQWMH/ZfNJeTGNl3koenvUwxfcXs+L6FSxIWSCh3kdIsAuvFRIQwg8n/5Dd9+xm6YKl1FnruOiNi7jm7Ws4fOKwy47j5wdz5hgnKjn7+d/Rcs6v8EywV9dXc+zksXZb7KtWQUyMa882tTZZefTLR0ldksrqgtX85oLfcPC+gzwx5wmGDBjiugMJj5BgF14vwC+AGyfcyM67d/L47Mf5eN/HTHh+Au/vft9lx8jMhJIS2L277bqkmCTAcy12x3FGxbZtsWttnG06Z47rhjnuPrabGf+Ywa+/+jULUhaw5549/OI7vyA6RK4Q0ldJsIs+IyQghJ+d9zO2LNpCQmQC85fN56FVD9Fka+r1vufaB/U6u7zAgKABDAkf4rEWu2MEjqMLqLm9e40PIFd1w6zYvYKpf5vKgaoDvHvtu/zr6n91OluT8H4S7KLPSRmUwvofrufOKXfyVNZTzF82n9pTbU+O6o7EROP2xRfO14+KHeW5Frv9A8RZV8w33xj3zsbcd4fWmie/eZKrll1lzO165zYWpCzo3U6F15BgF31SkH8Qz1/2PEsuWcLH+z7m4qUXc7zheK/2OXMmrFvXfj+7p4I9ryKPIeFDnJ6huHYtDBwIY8f2fP9aaxZ/vphH1jzCDeNv4Ktbv2JE5IheVCy8jQS76NPunno3b179JllFWcxbOq9X4Z6RYYxlP3iw7brkmGRKakqob+zgGr8ukl+Z77R/HSAry6izp8P6tdb8dNVP+d03v+OOKXfwxoI35CxQHyTBLvq8a8++lmXXLGND8QaufedaGm2NPdpPRoZxn5XVdl1yTDIazf7K/W1Xulh7Y9iPHYM9e87U2RNPr3+aP677Iz+a+iOev/R506/VI9xD/lWFT7g69Wqev/R5Vuat5J5P7mlzqdSuGD/euMSA02CP9cxY9jprHSXHS5yOYV+3zrjv6dUc38l5hwc/e5BrUq/h2YufldP+fZjvXWRb9Fu3T7md/Mp8fr/295wz5Bzunnp3t57v7w/Tp7ffYgfcfs2YgsoC43hOWuxr1xrXh0lP7/5+dx3dxS3v3cKMhBm8dtVr0lL3cfKvK3zKE3OeYN6oefzvf/6XHUd2dPv5GRmwbZsxO1FzcWFxRARFuH3I4+lgdzLUMSsLJk+G0G52iddZ67juneuICI7g3WvflT71fkCCXfgUP+XHK1e+QnRINNe9cx0nrd276OiMGWCzwcaNLZcrpTwyMuZgtfHLbeuJGE6dMmrqSTfM/f+5n11lu3jtqtcYOsDZ1ArC10iwC58zZMAQ3ljwBrnHcvnlF7/s1nOnTzfunXXHjIweSWF1oQsqbF9hdSHB/sEMCh/UYvnWrcak2zNmdG9/awrW8OLmF/l/Gf+P7476rgsrFd5Mgl34pLlJc7l98u08s/6ZFvPkdiY6GlJSYMOGtusskRaPBHtCVEKbPvAtW4z7qVO7vq/6xnru/PhORsWO4tELHnVhlcLbSbALn/Xk3CeJCY3hzo/uxKZtXX7e5MnGZXFbS4hK4Pip41TXV7uwypYKqwuxRLWdE3jLFuMKlN2ZLviJr58gryKP5y99XvrV+xkJduGzYkNj+WPmH1lXvI7Xtr3W5eelpUFxsTFuvDlH4Lqz1d5esGdnG3V1dYTigaoD/H7t77lpwk3MTepwdkvhgyTYhU+7ZeItTB0+lV99+SsaGhu69Jy0NOO+davd3cFubbJy6PghLJEtg91qhe3bjW8SXfXrL3+NQvHk3CddXKXoCyTYhU9TSvH47McprC7kpc0vdek5kyYZ962DPSEyAYCimiJXlnhayfESNLpNiz031xgV4/jA6UxOWQ6vb3+de6bdI1PX9VMS7MLnzU2aywUjL+Cxrx/r0lUgY2PhrLPaBvvUNKVNAAAXsElEQVTQAUMJ8AtwW4vdsd/Wwe744bSrLfaff/5zwgPDeXjWw64sT/QhEuzC5zla7Udrj/L8pue79Jy0tLbB7u/nT3xkvCnBHh4Oo0d3vo+dR3fy3u73eGDGA8SFxbmjTNEHSLCLfiEjIYMLRl7Asxue7dJFwtLSjEktWp+BmhCZ4LauGEewJ0QltFienW10D/l14d369LqnCQsM48fn/tgdJYo+QoJd9Bv3T7+fopoi3s15t9Nt09KM67JvbzUE3hLlvrHshdWFxIXFERYYdnqZzWacnNSV/vUjJ47wxo43uHXircSGxrqlRtE3SLCLfuOyMZcxKnYUT69/utNtOxoZU1JT4pLp+FpzNtQxL8/41tCV/vUlG5dgbbJy7/R7XV6b6Fsk2EW/4af8uO/c+9hQsoF1Res63HbECIiLcz4yxmqzcqT2iMvrcxbsjm8MEyd2/Nz6xnqe3/Q8l4+9nDEDx7i8NtG3SLCLfuXWSbcSGRzJC5tf6HA7pWDCBNi1q+Vyd41l11pzsPpgmzHsOTlGLePGdfz8FbtXcOzkMX48TfrWhQS76GfCg8K57uzreCfnnU6n0UtJMYK1+ZwdjmAvqnbtD6jVDdWcOHXC6Rj2kSMhLMz58xxe3voyligLsxNnu7Qu0TdJsIt+59ZJt3LSepJ3czv+ETU1FWpqoLT0zDLHiBVXt9jbG+qYk2PU0ZHimmI+y/+MhRMXygQaApBgF/3QjPgZjI4dzStbX+lwu5QU4z4n58yyqOAoIoIiPBLsjY3GHKedBfvr215Ho1k4caFLaxJ9lwS76HeUUiycuJCvDn7V4eTUjkDNzW35XEuUxeVj2feW7wVaTom3fz80NHQc7FprXt76Muefdb7T6fRE/yTBLvql7038HgrF69tfb3ebIUOM67M3b7EDJMUksfvYbpfWs+PoDoYOGNribFHHcTsK9s2lm9lXsU9a66IFlwS7UupBpZRWSsk5zKJPsERZyEjIYHnu8na3UcrojmneYgeYNmIaucdyqaqvclk9O47sYMLgCS2WOYLd0SXkzPLc5fgrf64ad5XLahF9X6+DXSmVAGQC7p1aRggXmz9uPtuObOu0O6Z1sM+IN+anW1+83iV1NNma2FW2y2mwJyRARITz52mteTf3XS5MvFDONBUtuKLF/jTwU0B3tqEQ3mR+ynwA3t/9frvbpKTA0aNQXn5m2bQR0/BTfp2e5NRV+ZX51DfWM2FI22DvqBsm91gue8v3smDcApfUIXxHQG+erJS6AijRWm9TXZ3aRQgvkRSTxDlDzuG93e9x/4z7nW7T/AfUWbOMP0cERzBh8ASeynqKl7Z07RrvHXFMANK8xW6zGcc8//z2n/de7nsAXDnuyl7XIHxLp8GulFoNDHWyajHwM+CirhxIKbUIWARg6c7EjUK40fxx8/nNV7/haO1RBocPbrO++ZBHR7CDMZ+qI1hdYVD4ICYNnXT68cGDUFfXcYt9+e7lzIifwfCI4S6rQ/iGToNda+10wkSl1AQgEXC01uOBLUqpaVrrw0728xLwEkB6erp02wivMH/cfB796lE+2PMBP5z8wzbrLRbjrM/W/ezzRs1j3qh5bqvLcbz2fjgtrC5kS+kWnpr7lNtqEH1Xj/vYtdY7tNaDtdYjtdYjgWJgsrNQF8JbnTPkHCxRFj7N+9Tpej8/GDu2bbC7W16ecd/e5Bqf5X8GwKVjLvVQRaIvkXHsol9TSpGZlMnn+z9v91K8o0ZBfr5n68rPhwEDYHDb3iEAVhWsYnjEcFLiOhgLKfotlwW7veV+zFX7E8JTMpMyqaqvYnPpZqfrk5PhwAHjFH9PycszjutsTEKTrYnVBavJTMpEBi0IZ6TFLvo9xxURV+Wvcro+OdkI9SL3zIjnVH6+8U3BmezD2VTUVXBRcpfGLYh+SIJd9HuDwgeRNjSN1ftXO12fbL8Ei6e6Y5qaoKDgzHFbc3wAzU1yOq5BCAl2IcAIybWFa6k9VdtmnaPl7KlgLy4Gq7X9FvtnBZ8xcchEp8MzhQAJdiEAo5/darPy34P/bbNuxAgIDvZcsDtGxDhrsdeeqmVt4VoykzI9U4zokyTYhQBmWWYR7B/M6oK23TF+fpCY6LlgdxzHWYt9XfE6rDYrc5LmeKYY0SdJsAsBhAaGMm3ENNYWrXW6PjnZsy32oCDjm0JrawvXolCnL0QmhDMS7ELYZSRksKV0C/WN9W3WJScbgas9cM50fj4kJYG/f9t1WcVZjB88nqiQKPcXIvosCXYh7DISMrDarGw+1HY8e3Iy1NYaV3p0N8cY9taabE2sK1rHzISZ7i9C9GkS7ELYObo3soqy2qzz1JBHrdsfw76rbBfHTx1npkWCXXRMgl0Iu0HhgxgdO5qsYvOC/cgR45uBsxa74wMnIyHDvUWIPk+CXYhmMhIyyCrKQrfqTE9MNE7vd3ewdzQiZm3RWoYOGEpidKJ7ixB9ngS7EM3MiJ/B0dqjFFQWtFgeHAzx8e4P9v32WfoSnWR3VlEWGQkZcn0Y0SkJdiGacXRzrCtuO+1dcrJxqr87FdpnDm49F83hE4cpqCyQH05Fl0iwC9FM6qBUIoMjnf6AarG4/0JghYUQF2dM7tHcxpKNAEyPn+7eAoRPkGAXohl/P38mD5vMltItbdZZLHDokHsv31tY2La1DrCldAsKxcQhE913cOEzJNiFaCVtaBrbjmyj0dYywRMSjCsvlpa679jtBvvhLYyLG0d4ULj7Di58hgS7EK2kDU2jvrGePcf2tFjuCFxHP7iraW1MYu0s2LNLs0kbluaeAwufI8EuRCuOAM0+nN1iuSNw3dXPXl0NJ060DfZjJ49RVFPE5KGT3XNg4XMk2IVoZVzcOEICQsgubRnsCQnGvbta7O2NiHHUIS120VUS7EK0EuAXwITBE9q02CMiIDra88Hu+CE3bagEu+gaCXYhnEgbmkb24ew2Z6C6c8hju8F+eAsjo0cSExrjngMLnyPBLoQTacPSqKqv4mD1wRbLExLc22IPDIQhQ1ouzy7NZvIw6V8XXSfBLoQTjm6P1v3sFot7gz0hwZixyaGmoYZ9Ffvkh1PRLRLsQjgxYcgE/JSf05ExFRXGFRhdzdkY9u1HtgMwaegk1x9Q+CwJdiGcCAsMY1zcOLYd2dZiuWNkjDv62Z0F+66juwDjg0aIrpJgF6IdqYNSySnLabHMXScpNTZCSUnbYM8py2FA0AASIhNce0Dh0yTYhWhHalwqBZUFLeZAdddJSocOgc3mJNiP5ZASlyKX6hXdIsEuRDtSBqVg0zb2le87vWz4cGPCDVe32B0fFM5a7KmDUl17MOHzJNiFaEdKXApAi+6YwEAj3F0d7I4JNpoHe1V9FYeOH5JgF90mwS5EO8YMHIOf8iP3WG6L5RaLcbEuV9q1y/jQaD4lXm6ZcVzHB4wQXSXBLkQ7QgNDSYxObPMD6tlnQ3a20SfuKjt2wLhxRrg7OI4rLXbRXQG93YFS6sfAPUAj8LHW+qc92Y/VaqW4uJj6+vrONzZRSEgI8fHxBDZ/BwqflTootU2LPSMD/v532LMHUlzUmN6xA2bNarkspyyHkIAQRkaPdM1BRL/Rq2BXSl0IXAmco7VuUEoN7um+iouLiYiIYOTIkV47AkBrTXl5OcXFxSQ6m21Y+JyUuBRW5q2k0dZIgJ/xdpkxw1iXleWaYK+uNvrsJ7Qaqp57LJdxcePw9/Pv/UFEv9LbFvtdwJNa6wYArfXRnu6ovr7eq0MdQCnFwIEDKSsrM7sU4SGpg1Kx2qwUVBYwZuAYAMaMgZgYeOutll0nPXXggHE/fnzL5TllOcy0yOTVovt6G+xjgPOUUo8D9cCDWuuNzjZUSi0CFgFYnE0RY2zTy3Lcry/UKFwnZdCZkTGOYPfzg7lz4d//htWrXXOcwECYMuXM4xOnTnCw+iC3x93umgOIfqXTYFdKrQaGOlm12P78GGA6MBV4WymVpFtf6xTQWr8EvASQnp7eZr038Pf3Z8KECTQ2NpKYmMjrr79OdHS02WUJE42LGwcYI1SuGnfV6eVvvAFPPum640RGQlzcmce7j+0G5IdT0TOdBrvWem5765RSdwHL7UH+rVLKBsQBfbKvIjQ0lK1btwKwcOFClixZwuLFi02uSpgpMjiS+Mh4co61HBkTFARJSe47rmO+1bFxY913EOGzejvc8X1gNoBSagwQBBzrbVHeYMaMGZSUlJhdhvACYwaOaXH2qSfkV+ajUCTFuPHTQ/is3vax/xP4p1JqJ3AKWOisG6a77rsP7A1nl5k0CZ55pmvbNjU1sWbNGn7wgx+4tgjRJ42KGcXy3cs9esy8ijxGRI4gJCDEo8cVvqFXLXat9Smt9c1a6/Fa68la689dVZgZ6urqmDRpEgMHDqSiooLMzEyzSxJeIDk2mWMnj1HTUOOxY+ZX5jMqdlTnGwrhRK9PUHKHrrasXc3Rx15dXc1ll13GkiVL+MlPfmJOMcJrJMckA5BfkU/aMM9MKJ1XkcflYy73yLGE75FLCjgRFRXFs88+yx//+EesVqvZ5QiTJcfag70y3yPHO95wnKO1R6XFLnpMgr0daWlpTJw4kbfeesvsUoTJmrfYPcHxAeI4rhDd5ZVdMWY5ceJEi8cffvihSZUIbxIRHMGgsEHkVeR55HiODxBpsYuekha7EF2QHJvssa4YxweIowtIiO6SYBeiC5JjPBfs+ZX5DAobRGRwpEeOJ3yPBLsQXZAck0xRdRENjQ1uP1ZeRZ601kWvSLAL0QXJscloNAeqDrj9WDKGXfSWBLsQXXB6ZIybu2MaGhsoqi6SETGiVyTYhegCRwva3UMe91ftR6OlxS56RYJdiC4YHD6Y8MBwt7fYHR8c0mIXvSHBLkQXKKU8MuTxYPVBAJnnVPSKBHszb7zxBtOmTWPSpEnccccdNDU1mV2S8CIjo0dysOqgW49RWF1IoF8gQwYMcetxhG/zyjNP71t5H1sPu/a6vZOGTuKZee1fXSw3N5dly5axdu1aAgMDufvuu1m6dCm33HKLS+sQfZcl0sJ/D/7XrccorC4kISoBPyVtLtFzXhnsZlizZg2bN29m6tSpgHEJ38GDB5tclfAmCVEJVNVXUdNQ47aThwqrC7FEOZ8TWIiu8spg76hl7S5aaxYuXMjvfvc7jx9b9A2OwC2qLuLswWe75RiF1YVcmHihW/Yt+g/5vmc3Z84c3nnnHY4ePQpARUUFBw+6tz9V9C2ng72myC37b7Q1UnK8BEuktNhF70iw26WmpvLYY49x0UUXcc4555CZmUlpaanZZQkvkhCZABitanc4dPwQNm2TrhjRa17ZFWOW6667juuuu87sMoSXGhYxDH/l77Zgd+xXgl30lrTYheiiAL8ARkSOcFtXjAS7cBUJdiG6ISEywe0t9oSoBLfsX/QfEuxCdIMlyuLWYI8NjWVA0AC37F/0HxLsQnSDJcpCcU0xNm1z+b5lDLtwFQl2IbohITKBU02nOFp71OX7lmAXriLBLkQ3OILXHd0xhdWFMoZduIQEezPPPvssKSkp3HTTTWaXIrxU87NPXammoYbqhmppsQuXkHHszTz33HN8+umnJCYmml2K8FKOESuubrE7Pigk2IUrSIvd7s4776SgoIArrriCp59+2uxyhJeKCYkhPDDc5cEuY9iFK3lli92My/a+8MILrFy5ki+++IK4uDiXHlv4DqUUliiLy09S2lu+F4DEGPm2KHpPWuxCdFNiTOLpIHaVHUd3EBcWx5BwmWBD9F6vWuxKqUnAC0AI0AjcrbX+trdFmXHZXiG6aurwqazMW+nS67LvOLqDCYMnoJRyyf5E/9bbFvtTwKNa60nAL+2PhfBpM+JnYNM2vi3pdRsGAJu2sevoLiYMnuCS/QnR22DXgKPJEgUc6uX+hPB658afi0KxrmidS/a3v3I/tdZaJgyRYBeu0dsfT+8D/qOU+iPGh0RG70syz4EDB8wuQfQB0SHRpA5K5U/r/sRbu97q9f5qT9UCSItduEynwa6UWg0MdbJqMTAHuF9r/a5S6lrgH8DcdvazCFgEYLHIkC7Rt/36gl+zbNcyl+3vktGXMHnYZJftT/RvSmvd8ycrVQ1Ea621Mn71qdZad/prUnp6ut60aVOLZbm5uaSkpPS4Fk/qS7UKIXyHUmqz1jq9s+1628d+CPiO/c+zgX293J8QQohe6m0f++3AX5RSAUA99q6WntJae/1wr958wxFCCE/oVbBrrb8BpriikJCQEMrLyxk4cKDXhrvWmvLyckJCQswuRQgh2uU1lxSIj4+nuLiYsrIys0vpUEhICPHx8WaXIYQQ7fKaYA8MDJSrKgohhAvItWKEEMLHSLALIYSPkWAXQggf06sTlHp8UKXKgIM9fHoccMyF5biDt9fo7fWB99fo7fWB1OgK3lbfWVrrQZ1tZEqw94ZSalNXzrwyk7fX6O31gffX6O31gdToCt5eX3ukK0YIIXyMBLsQQviYvhjsL5ldQBd4e43eXh94f43eXh9Ija7g7fU51ef62IUQQnSsL7bYhRBCdKBPBbtSap5Sao9SKk8p9bAX1JOglPpCKZWrlNqllLrXvjxWKbVKKbXPfh/jBbX6K6WylVIf2R8nKqU22GtcppQKMrG2aKXUO0qp3fbXcoa3vYZKqfvt/8Y7lVJvKqVCzH4NlVL/VEodVUrtbLbM6eumDM/a3zvblVJun9Wjnfr+YP933q6Uek8pFd1s3SP2+vYopb7r7vraq7HZugeVUlopFWd/7PHXsKf6TLArpfyBJcDFQCpwg1Iq1dyqaAQe0FqnANOBH9lrehhYo7UeDayxPzbbvUBus8e/B56211gJ/MCUqgx/AVZqrccBEzHq9JrXUCk1AvgJkK61Hg/4A9dj/mv4CjCv1bL2XreLgdH22yLgeZPqWwWM11qfA+wFHgGwv2+uB862P+c5+3vejBpRSiUAmUBhs8VmvIY9o7XuEzdgBvCfZo8fAR4xu65WNa7A+M+wBxhmXzYM2GNyXfEYb/LZwEeAwjjpIsDZa+vh2iKB/dh/72m23GteQ2AEUATEYlw47yPgu97wGgIjgZ2dvW7Ai8ANzrbzZH2t1s0Hltr/3OL9DPwHmGHGa2hf9g5GI+MAEGfma9iTW59psXPmzeVQbF/mFZRSI4E0YAMwRGtdCmC/H2xeZQA8A/wUsNkfDwSqtNaN9sdmvpZJQBnwsr2r6O9KqXC86DXUWpcAf8RovZUC1cBmvOc1bK69180b3z/fBz61/9lr6lNKXQGUaK23tVrlNTV2pi8Fu7PZN7xiSI9SagDwLnCf1rrG7HqaU0pdBhzVWm9uvtjJpma9lgHAZOB5rXUaUIt3dF2dZu+nvhJIBIYD4Rhfy1vziv+P7fCmf3OUUosxujKXOhY52czj9SmlwoDFwC+drXayzCv/zftSsBcDCc0ex2PMuWoqpVQgRqgv1Vovty8+opQaZl8/DDhqVn3ATOAKpdQB4C2M7phngGj7lIZg7mtZDBRrrTfYH7+DEfTe9BrOBfZrrcu01lZgOZCB97yGzbX3unnN+0cptRC4DLhJ2/s08J76kjE+wLfZ3zPxwBal1FC8p8ZO9aVg3wiMto9ECML4oeUDMwtSSingH0Cu1vrPzVZ9ACy0/3khRt+7KbTWj2it47XWIzFes8+11jcBXwDX2DczrUat9WGgSCk11r5oDpCDF72GGF0w05VSYfZ/c0eNXvEattLe6/YBcIt9ZMd0oNrRZeNJSql5wEPAFVrrk81WfQBcr5QKVkolYvxA+a2n69Na79BaD9Zaj7S/Z4qByfb/p17xGnaJ2Z383fyR4xKMX9LzgcVeUM8sjK9i24Gt9tslGH3Ya4B99vtYs2u113sB8JH9z0kYb5w84N9AsIl1TQI22V/H94EYb3sNgUeB3cBO4HUg2OzXEHgTo8/fihFAP2jvdcPoRlhif+/swBjhY0Z9eRj91I73ywvNtl9sr28PcLFZr2Gr9Qc48+Opx1/Dnt7kzFMhhPAxfakrRgghRBdIsAshhI+RYBdCCB8jwS6EED5Ggl0IIXyMBLsQQvgYCXYhhPAxEuxCCOFj/j8buWHhlSWfbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f794d0328d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posx_path = np.linspace(0, 150, 300)\n",
    "x_nominal = [[posx_path[i], nominal(posx_path[i])[0], 10, nominal(posx_path[i])[1]] for i in range(300)]\n",
    "x_barrier_u = [[posx_path[i], barrier_u(posx_path[i])[1], 10, barrier_u(posx_path[i])[1]] for i in range(300)]\n",
    "x_barrier_l = [[posx_path[i], barrier_l(posx_path[i])[1], 10, barrier_l(posx_path[i])[1]] for i in range(300)]\n",
    "\n",
    "\n",
    "posx_ = np.asarray(x_nominal)[:, 0]\n",
    "posy_ = np.asarray(x_nominal)[:, 1]\n",
    "posy_u = np.asarray(x_barrier_u)[:, 1]\n",
    "posy_l = np.asarray(x_barrier_l)[:, 1]\n",
    "_ = plt.plot(posx_, posy_, \"b\")\n",
    "_ = plt.plot(posx_, posy_u, 'g')\n",
    "_ = plt.plot(posx_, posy_l, 'g')\n",
    "_ = plt.legend(\"Reference Path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/lib/python3/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] avg_loss: 0.684\n",
      "[Epoch 6] avg_loss: 0.684\n",
      "[Epoch 11] avg_loss: 0.683\n",
      "[Epoch 16] avg_loss: 0.685\n",
      "[Epoch 21] avg_loss: 0.686\n",
      "[Epoch 26] avg_loss: 0.683\n",
      "[Epoch 31] avg_loss: 0.684\n",
      "[Epoch 36] avg_loss: 0.684\n",
      "[Epoch 41] avg_loss: 0.685\n",
      "[Epoch 46] avg_loss: 0.685\n",
      "[Epoch 51] avg_loss: 0.684\n",
      "[Epoch 56] avg_loss: 0.686\n",
      "[Epoch 61] avg_loss: 0.687\n",
      "[Epoch 66] avg_loss: 0.684\n",
      "[Epoch 71] avg_loss: 0.684\n",
      "[Epoch 76] avg_loss: 0.684\n",
      "[Epoch 81] avg_loss: 0.685\n",
      "[Epoch 86] avg_loss: 0.684\n",
      "[Epoch 91] avg_loss: 0.683\n",
      "[Epoch 96] avg_loss: 0.683\n",
      "[Epoch 101] avg_loss: 0.684\n",
      "[Epoch 106] avg_loss: 0.684\n",
      "[Epoch 111] avg_loss: 0.683\n",
      "[Epoch 116] avg_loss: 0.684\n",
      "[Epoch 121] avg_loss: 0.685\n",
      "[Epoch 126] avg_loss: 0.683\n",
      "[Epoch 131] avg_loss: 0.685\n",
      "[Epoch 136] avg_loss: 0.683\n",
      "[Epoch 141] avg_loss: 0.684\n",
      "[Epoch 146] avg_loss: 0.684\n",
      "[Epoch 151] avg_loss: 0.684\n",
      "[Epoch 156] avg_loss: 0.683\n",
      "[Epoch 161] avg_loss: 0.684\n",
      "[Epoch 166] avg_loss: 0.683\n",
      "[Epoch 171] avg_loss: 0.685\n",
      "[Epoch 176] avg_loss: 0.684\n",
      "[Epoch 181] avg_loss: 0.684\n",
      "[Epoch 186] avg_loss: 0.683\n",
      "[Epoch 191] avg_loss: 0.683\n",
      "[Epoch 196] avg_loss: 0.684\n",
      "[Epoch 201] avg_loss: 0.684\n",
      "[Epoch 206] avg_loss: 0.683\n",
      "[Epoch 211] avg_loss: 0.682\n",
      "[Epoch 216] avg_loss: 0.683\n",
      "[Epoch 221] avg_loss: 0.684\n",
      "[Epoch 226] avg_loss: 0.682\n",
      "[Epoch 231] avg_loss: 0.684\n",
      "[Epoch 236] avg_loss: 0.684\n",
      "[Epoch 241] avg_loss: 0.683\n",
      "[Epoch 246] avg_loss: 0.684\n",
      "[Epoch 251] avg_loss: 0.684\n",
      "[Epoch 256] avg_loss: 0.683\n",
      "[Epoch 261] avg_loss: 0.682\n",
      "[Epoch 266] avg_loss: 0.684\n",
      "[Epoch 271] avg_loss: 0.682\n",
      "[Epoch 276] avg_loss: 0.684\n",
      "[Epoch 281] avg_loss: 0.682\n",
      "[Epoch 286] avg_loss: 0.682\n",
      "[Epoch 291] avg_loss: 0.684\n",
      "[Epoch 296] avg_loss: 0.683\n",
      "[Epoch 301] avg_loss: 0.684\n",
      "[Epoch 306] avg_loss: 0.682\n",
      "[Epoch 311] avg_loss: 0.684\n",
      "[Epoch 316] avg_loss: 0.683\n",
      "[Epoch 321] avg_loss: 0.682\n",
      "[Epoch 326] avg_loss: 0.684\n",
      "[Epoch 331] avg_loss: 0.684\n",
      "[Epoch 336] avg_loss: 0.685\n",
      "[Epoch 341] avg_loss: 0.683\n",
      "[Epoch 346] avg_loss: 0.683\n",
      "[Epoch 351] avg_loss: 0.683\n",
      "[Epoch 356] avg_loss: 0.682\n",
      "[Epoch 361] avg_loss: 0.683\n",
      "[Epoch 366] avg_loss: 0.683\n",
      "[Epoch 371] avg_loss: 0.682\n",
      "[Epoch 376] avg_loss: 0.682\n",
      "[Epoch 381] avg_loss: 0.683\n",
      "[Epoch 386] avg_loss: 0.683\n",
      "[Epoch 391] avg_loss: 0.684\n",
      "[Epoch 396] avg_loss: 0.685\n",
      "[Epoch 401] avg_loss: 0.682\n",
      "[Epoch 406] avg_loss: 0.683\n",
      "[Epoch 411] avg_loss: 0.683\n",
      "[Epoch 416] avg_loss: 0.683\n",
      "[Epoch 421] avg_loss: 0.682\n",
      "[Epoch 426] avg_loss: 0.682\n",
      "[Epoch 431] avg_loss: 0.682\n",
      "[Epoch 436] avg_loss: 0.685\n",
      "[Epoch 441] avg_loss: 0.686\n",
      "[Epoch 446] avg_loss: 0.683\n",
      "[Epoch 451] avg_loss: 0.683\n",
      "[Epoch 456] avg_loss: 0.687\n",
      "[Epoch 461] avg_loss: 0.682\n",
      "[Epoch 466] avg_loss: 0.683\n",
      "[Epoch 471] avg_loss: 0.684\n",
      "[Epoch 476] avg_loss: 0.681\n",
      "[Epoch 481] avg_loss: 0.682\n",
      "[Epoch 486] avg_loss: 0.682\n",
      "[Epoch 491] avg_loss: 0.682\n",
      "[Epoch 496] avg_loss: 0.682\n",
      "[Epoch 501] avg_loss: 0.682\n",
      "[Epoch 506] avg_loss: 0.681\n",
      "[Epoch 511] avg_loss: 0.682\n",
      "[Epoch 516] avg_loss: 0.682\n",
      "[Epoch 521] avg_loss: 0.683\n",
      "[Epoch 526] avg_loss: 0.681\n",
      "[Epoch 531] avg_loss: 0.684\n",
      "[Epoch 536] avg_loss: 0.682\n",
      "[Epoch 541] avg_loss: 0.685\n",
      "[Epoch 546] avg_loss: 0.684\n",
      "[Epoch 551] avg_loss: 0.683\n",
      "[Epoch 556] avg_loss: 0.685\n",
      "[Epoch 561] avg_loss: 0.684\n",
      "[Epoch 566] avg_loss: 0.683\n",
      "[Epoch 571] avg_loss: 0.681\n",
      "[Epoch 576] avg_loss: 0.684\n",
      "[Epoch 581] avg_loss: 0.682\n",
      "[Epoch 586] avg_loss: 0.684\n",
      "[Epoch 591] avg_loss: 0.681\n",
      "[Epoch 596] avg_loss: 0.684\n",
      "[Epoch 601] avg_loss: 0.682\n",
      "[Epoch 606] avg_loss: 0.685\n",
      "[Epoch 611] avg_loss: 0.681\n",
      "[Epoch 616] avg_loss: 0.683\n",
      "[Epoch 621] avg_loss: 0.686\n",
      "[Epoch 626] avg_loss: 0.683\n",
      "[Epoch 631] avg_loss: 0.681\n",
      "[Epoch 636] avg_loss: 0.684\n",
      "[Epoch 641] avg_loss: 0.681\n",
      "[Epoch 646] avg_loss: 0.681\n",
      "[Epoch 651] avg_loss: 0.682\n",
      "[Epoch 656] avg_loss: 0.684\n",
      "[Epoch 661] avg_loss: 0.681\n",
      "[Epoch 666] avg_loss: 0.683\n",
      "[Epoch 671] avg_loss: 0.682\n",
      "[Epoch 676] avg_loss: 0.682\n",
      "[Epoch 681] avg_loss: 0.684\n",
      "[Epoch 686] avg_loss: 0.681\n",
      "[Epoch 691] avg_loss: 0.682\n",
      "[Epoch 696] avg_loss: 0.686\n",
      "[Epoch 701] avg_loss: 0.684\n",
      "[Epoch 706] avg_loss: 0.683\n",
      "[Epoch 711] avg_loss: 0.681\n",
      "[Epoch 716] avg_loss: 0.682\n",
      "[Epoch 721] avg_loss: 0.682\n",
      "[Epoch 726] avg_loss: 0.681\n",
      "[Epoch 731] avg_loss: 0.683\n",
      "[Epoch 736] avg_loss: 0.682\n",
      "[Epoch 741] avg_loss: 0.683\n",
      "[Epoch 746] avg_loss: 0.682\n",
      "[Epoch 751] avg_loss: 0.682\n",
      "[Epoch 756] avg_loss: 0.682\n",
      "[Epoch 761] avg_loss: 0.681\n",
      "[Epoch 766] avg_loss: 0.684\n",
      "[Epoch 771] avg_loss: 0.683\n",
      "[Epoch 776] avg_loss: 0.684\n",
      "[Epoch 781] avg_loss: 0.681\n",
      "[Epoch 786] avg_loss: 0.682\n",
      "[Epoch 791] avg_loss: 0.682\n",
      "[Epoch 796] avg_loss: 0.682\n",
      "[Epoch 801] avg_loss: 0.682\n",
      "[Epoch 806] avg_loss: 0.682\n",
      "[Epoch 811] avg_loss: 0.681\n",
      "[Epoch 816] avg_loss: 0.680\n",
      "[Epoch 821] avg_loss: 0.682\n",
      "[Epoch 826] avg_loss: 0.684\n",
      "[Epoch 831] avg_loss: 0.681\n",
      "[Epoch 836] avg_loss: 0.681\n",
      "[Epoch 841] avg_loss: 0.681\n",
      "[Epoch 846] avg_loss: 0.681\n",
      "[Epoch 851] avg_loss: 0.681\n",
      "[Epoch 856] avg_loss: 0.683\n",
      "[Epoch 861] avg_loss: 0.683\n",
      "[Epoch 866] avg_loss: 0.684\n",
      "[Epoch 871] avg_loss: 0.681\n",
      "[Epoch 876] avg_loss: 0.681\n",
      "[Epoch 881] avg_loss: 0.681\n",
      "[Epoch 886] avg_loss: 0.681\n",
      "[Epoch 891] avg_loss: 0.681\n",
      "[Epoch 896] avg_loss: 0.681\n",
      "[Epoch 901] avg_loss: 0.681\n",
      "[Epoch 906] avg_loss: 0.682\n",
      "[Epoch 911] avg_loss: 0.684\n",
      "[Epoch 916] avg_loss: 0.682\n",
      "[Epoch 921] avg_loss: 0.683\n",
      "[Epoch 926] avg_loss: 0.683\n",
      "[Epoch 931] avg_loss: 0.682\n",
      "[Epoch 936] avg_loss: 0.680\n",
      "[Epoch 941] avg_loss: 0.681\n",
      "[Epoch 946] avg_loss: 0.682\n",
      "[Epoch 951] avg_loss: 0.683\n",
      "[Epoch 956] avg_loss: 0.682\n",
      "[Epoch 961] avg_loss: 0.684\n",
      "[Epoch 966] avg_loss: 0.684\n",
      "[Epoch 971] avg_loss: 0.681\n",
      "[Epoch 976] avg_loss: 0.684\n",
      "[Epoch 981] avg_loss: 0.684\n",
      "[Epoch 986] avg_loss: 0.683\n",
      "[Epoch 991] avg_loss: 0.683\n",
      "[Epoch 996] avg_loss: 0.683\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "agent = NeuralNetwork(input_size = (n + 1) * 4, model_name = 'mlp_H2', batch_size = 100)#, checkpoint = 'checkpoints/mlp_H2_995.pt')\n",
    "\n",
    "agent.data_process(paths = ['expert_traj/expert_pts_10058_H10.p', 'expert_traj/expert_pts_17358_H10.p'])\n",
    "agent.train(num_epoch = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/lib/python3/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent_traj = []\n",
    "batch_size = 5\n",
    "for i_batch in range(batch_size):\n",
    "    agent_traj.append([])\n",
    "    x0 = [x_nominal[0][0] + 1.0 * (2 * random.random() - 1.0), \\\n",
    "          x_nominal[0][1] + 3.0 * (2 * random.random() - 1.0), \\\n",
    "          x_nominal[0][2] + 1.0 * (2 * random.random() - 1.0), \\\n",
    "          x_nominal[0][3] + 3.0 * (2 * random.random() - 1.0)]  # Initial state.\n",
    "\n",
    "    N = 300\n",
    "    H = 2\n",
    "    \n",
    "    for _ in range(0, N):\n",
    "        i = abs(int(x0[0]/0.5))\n",
    "        x_nn = []\n",
    "        if i >= N - H - 1:\n",
    "            break\n",
    "        x_nominal_ = x_nominal[i: i + H]\n",
    "        for j in [x0] + x_nominal_[:]:\n",
    "            for k in j:\n",
    "                x_nn.append(k)\n",
    "        u = agent.run([x_nn])\n",
    "        agent_traj[-1] = agent_traj[-1] + [[x0[:], u[0]]]\n",
    "        x1 = dynamics.f(x0, u[0], i)[0]        \n",
    "        x0 = x1[:]\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red curve in the plot shows the trajectory of the regression model controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f794c045470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_agent_traj(x_path, agent_traj):\n",
    "    plt.title(\"Trajectory of the two omnidirectional vehicles\")\n",
    "    plt.legend([\"Vehicle\", \"Reference Path\"])\n",
    "    \n",
    "    posx_ = np.asarray(x_path)[:, 0]\n",
    "    posy_ = np.asarray(x_path)[:, 1]\n",
    "    posy_u = np.asarray(x_barrier_u)[:, 1]\n",
    "    posy_l = np.asarray(x_barrier_l)[:, 1]\n",
    "    _ = plt.plot(posx_, posy_, \"b\")\n",
    "    _ = plt.plot(posx_, posy_u, 'g')\n",
    "    _ = plt.plot(posx_, posy_l, 'g')\n",
    "    _ = plt.legend(\"Reference Path\")\n",
    "\n",
    "    posx = []\n",
    "    posy = []\n",
    "    v = []\n",
    "    theta = []\n",
    "    for i in agent_traj:\n",
    "        posx.append([])\n",
    "        posy.append([])\n",
    "        v.append([])\n",
    "        theta.append([])\n",
    "        for j in i:\n",
    "            posx[-1].append(j[0][0])\n",
    "            posy[-1].append(j[0][1])\n",
    "            v[-1].append(j[0][2])\n",
    "            theta[-1].append(j[0][3])\n",
    "            plt.plot(posx[-1], posy[-1], \"r\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "draw_agent_traj(x_nominal, agent_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>Step 0 at [0.071707415378427619, -0.15047527561433305, 9.836748180556448, -2.6386438812866029]\n",
      "iteration 0 accepted [  8.74306331e+55] [ 10.95247354  -0.2400638   10.27114705  -0.04716368] [ 0.31258267  0.05244622]\n",
      "Utilize MPC output [-28.97638702   2.69310331]\n",
      ">>>>>Step 1 at [-0.35812812 -0.38694392  9.78674818 -2.15129049]\n",
      "iteration 0 accepted [  7.45083105e+23] [ 12.38241005  -0.15790474  10.22271625  -0.04350132] [ 0.02615157 -0.0523413 ]\n",
      "Utilize MPC output [  1.36153927e+22   8.93670103e+20]\n",
      ">>>>>Step 2 at [-0.62718451 -0.79716906  9.83674818 -1.66195308]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/lib/python3/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/depend/workspace/MPSC_Guided_Imitation_Learning/ilqr/ilqr/controller.py:161: UserWarning: Singular matrix\n",
      "  warnings.warn(str(e))\n",
      "/home/depend/workspace/MPSC_Guided_Imitation_Learning/ilqr/ilqr/controller.py:168: UserWarning: exceeded max regularization term\n",
      "  warnings.warn(\"exceeded max regularization term\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 accepted [  1.07037196e+38] [ 12.91140403  -0.16360378  10.22387527  -0.04081889] [ 0.0983356 -0.3545422]\n",
      "Utilize MPC output [  6.09714386e+12   9.78796626e+10]\n",
      ">>>>>Step 3 at [-0.67207054 -1.28820922  9.88674818 -1.17011567]\n",
      "iteration 0 accepted [  1.08751569e+31] [ 13.4728023   -0.58583257  10.23938855  -0.03654036] [ 0.23136708 -0.12980154]\n",
      "Utilize MPC output [-1.16443455  0.90253383]\n",
      ">>>>>Step 4 at [-0.47965762 -1.74244632  9.84562419 -0.81541405]\n",
      "iteration 0 accepted [  9.39377120e+27] [ 11.30124005  -0.70964469  10.22098042  -0.023095  ] [ 1.46673441 -0.51041341]\n",
      "Utilize MPC output [-541.5736084     2.57876015]\n",
      ">>>>>Step 5 at [-0.14302282 -2.09992171  9.79562419 -0.32876751]\n",
      "iteration 0 accepted [  2.51502252e+25] [ 14.32198393  -0.63277043  10.15453919  -0.03940783] [ 0.20820028 -0.17136133]\n",
      "Utilize MPC output [-50954.9453125     58.7868576]\n",
      ">>>>>Step 6 at [ 0.31934315 -2.2576571   9.74562419  0.1610137 ]\n",
      "iteration 0 converged [  7.87239577e+18] [ 14.80348198  -0.42708895  10.13743337  -0.0365103 ] [ 0.21736917 -0.07300372]\n",
      "Utilize MPC output [  6460.81396484  96975.6171875 ]\n",
      ">>>>>Step 7 at [ 0.80155534 -2.17933633  9.79562419  0.64829491]\n",
      "Utilize NN output [[ 0.42269892 -0.04718481]]\n",
      ">>>>>Step 8 at [ 1.19236483 -1.88329134  9.81558427  0.62520182]\n",
      "Utilize NN output [[ 0.46905962 -0.0974666 ]]\n",
      ">>>>>Step 9 at [ 1.59075408 -1.59573742  9.83745623  0.57751813]\n",
      "Utilize NN output [[ 0.48069432 -0.12469146]]\n",
      ">>>>>Step 10 at [ 2.00332298 -1.32689639  9.85979621  0.51650169]\n",
      "Utilize NN output [[ 0.48510841 -0.13247073]]\n",
      ">>>>>Step 11 at [ 2.43249278 -1.08315972  9.88231248  0.45157432]\n",
      "Utilize NN output [[ 0.3104513  -0.12152896]]\n",
      ">>>>>Step 12 at [ 2.87741721 -0.86737216  9.89735486  0.39181886]\n",
      "Utilize NN output [[ 0.30742258 -0.12155527]]\n",
      ">>>>>Step 13 at [ 3.33512629 -0.67825469  9.91225938  0.33195961]\n",
      "Utilize NN output [[ 0.30080438 -0.12339   ]]\n",
      ">>>>>Step 14 at [ 3.80402666 -0.5166173   9.92686181  0.2711144 ]\n",
      "Utilize NN output [[ 0.29090047 -0.11941849]]\n",
      ">>>>>Step 15 at [ 4.28258064 -0.38359926  9.94100998  0.21212202]\n",
      "Utilize NN output [[ 0.27919921 -0.11070357]]\n",
      ">>>>>Step 16 at [ 4.768823   -0.2788812   9.95461817  0.15732044]\n",
      "Utilize NN output [[ 0.2705664  -0.09415612]]\n",
      ">>>>>Step 17 at [ 5.26073337 -0.20084882  9.96782576  0.11059402]\n",
      "Utilize NN output [[ 0.26148254 -0.07782917]]\n",
      ">>>>>Step 18 at [ 5.75639749 -0.14580674  9.98060984  0.07188277]\n",
      "Utilize NN output [[ 0.25252417 -0.06223626]]\n",
      ">>>>>Step 19 at [ 6.25444757 -0.10994373  9.99297434  0.04086502]\n",
      "Utilize NN output [[ 0.24402198 -0.04795285]]\n",
      ">>>>>Step 20 at [  6.75397801  -0.08951904  10.00493889   0.01692379]\n",
      "Utilize NN output [[ 0.2361186  -0.03534403]]\n",
      ">>>>>Step 21 at [  7.25444306e+00  -8.10484676e-02   1.00165302e+01  -7.49596639e-04]\n",
      "Utilize NN output [[ 0.22883371 -0.02458986]]\n",
      ">>>>>Step 22 at [  7.75555059  -0.0814241   10.02777628  -0.01306237]\n",
      "Utilize NN output [[ 0.22342327 -0.01984464]]\n",
      ">>>>>Step 23 at [  8.25717132  -0.08797682  10.0387652   -0.02301094]\n",
      "Utilize NN output [[ 0.21845548 -0.01447587]]\n",
      ">>>>>Step 24 at [  8.75924544  -0.09953206  10.04951747  -0.03027643]\n",
      "Utilize NN output [[ 0.21379326 -0.00998684]]\n",
      ">>>>>Step 25 at [  9.26175415  -0.11475088  10.06004719  -0.03529441]\n",
      "Utilize NN output [[ 0.2092862  -0.00651182]]\n",
      ">>>>>Step 26 at [  9.76470094  -0.13250946  10.07036135  -0.03856982]\n",
      "Utilize NN output [[ 0.20572257 -0.00553359]]\n",
      ">>>>>Step 27 at [ 10.26809793  -0.15193503  10.08050478  -0.04135606]\n",
      "Utilize NN output [[ 0.20249233 -0.00305488]]\n",
      ">>>>>Step 28 at [ 10.7719417   -0.1727839   10.09049325  -0.04289579]\n",
      "Utilize NN output [[ 0.19881919 -0.00136325]]\n",
      ">>>>>Step 29 at [ 11.27624734  -0.19442977  10.10030526  -0.04358358]\n",
      "Utilize NN output [[ 0.19523099 -0.0002431 ]]\n",
      ">>>>>Step 30 at [ 11.78102379  -0.21644367  10.10994466  -0.04370635]\n",
      "Utilize NN output [[ 0.19152221  0.00020821]]\n",
      ">>>>>Step 31 at [ 12.28627458  -0.23854041  10.11940537  -0.04360109]\n",
      "Utilize NN output [[ 0.1878854   0.00175518]]\n",
      ">>>>>Step 32 at [ 12.79199589  -0.2606044   10.12869064  -0.04271303]\n",
      "Utilize NN output [[ 0.18455838  0.00344603]]\n",
      ">>>>>Step 33 at [ 13.29819643  -0.28223891  10.13781519  -0.04096785]\n",
      "Utilize NN output [[ 0.18133418  0.00401533]]\n",
      ">>>>>Step 34 at [ 13.8048859   -0.30300851  10.14678381  -0.03893252]\n",
      "Utilize NN output [[ 0.17811184  0.00416327]]\n",
      ">>>>>Step 35 at [ 14.31206079  -0.32276409  10.15559641  -0.03682034]\n",
      "Utilize NN output [[ 0.17489038  0.00403485]]\n",
      ">>>>>Step 36 at [ 14.81971271  -0.34146446  10.16425285  -0.03477154]\n",
      "Utilize NN output [[ 0.17166856  0.00372822]]\n",
      ">>>>>Step 37 at [ 15.32783053  -0.35913962  10.17275295  -0.03287682]\n",
      "Utilize NN output [[ 0.16844836  0.003319  ]]\n",
      ">>>>>Step 38 at [ 15.83640179  -0.37586585  10.1810966   -0.03118865]\n",
      "Utilize NN output [[ 0.16523197  0.00286207]]\n",
      ">>>>>Step 39 at [ 16.34541363  -0.3917464   10.18928382  -0.02973171]\n",
      "Utilize NN output [[ 0.16202705  0.0023971 ]]\n",
      ">>>>>Step 40 at [ 16.85485336  -0.40689738  10.19731502  -0.02851047]\n",
      "Utilize NN output [[ 0.15883721  0.00195388]]\n",
      ">>>>>Step 41 at [ 17.36470871  -0.42143753  10.20519076  -0.02751426]\n",
      "Utilize NN output [[ 0.15566866  0.0015478 ]]\n",
      ">>>>>Step 42 at [ 17.87496808  -0.43548048  10.21291192  -0.02672448]\n",
      "Utilize NN output [[ 0.15252598  0.00118878]]\n",
      ">>>>>Step 43 at [ 18.38562046  -0.44913065  10.22047963  -0.02611743]\n",
      "Utilize NN output [[ 0.14941624  0.00088167]]\n",
      ">>>>>Step 44 at [ 18.89665549  -0.46248061  10.22789533  -0.02566688]\n",
      "Utilize NN output [[ 0.14634173  0.00062585]]\n",
      ">>>>>Step 45 at [ 19.40806339  -0.47560973  10.23516063  -0.02534682]\n",
      "Utilize NN output [[ 0.14330767  0.00041783]]\n",
      ">>>>>Step 46 at [ 19.9198349   -0.48858429  10.24227736  -0.02513299]\n",
      "Utilize NN output [[ 0.14031558  0.00025365]]\n",
      ">>>>>Step 47 at [ 20.43196123  -0.50145827  10.24924746  -0.0250031 ]\n",
      "Utilize NN output [[ 0.13448873  0.00745754]]\n",
      ">>>>>Step 48 at [ 20.94443048  -0.51427426  10.25593164  -0.02118146]\n",
      "Utilize NN output [[ 0.12890142  0.01257094]]\n",
      ">>>>>Step 49 at [  2.14572722e+01  -5.25138623e-01   1.02623413e+01  -1.47354649e-02]\n",
      "Utilize NN output [[ 0.1236365   0.01559481]]\n",
      ">>>>>Step 50 at [  2.19704873e+01  -5.32701633e-01   1.02684918e+01  -6.73414930e-03]\n",
      "Utilize NN output [[ 0.11852937  0.0167172 ]]\n",
      ">>>>>Step 51 at [  2.24840477e+01  -5.36160078e-01   1.02743906e+01   1.84807429e-03]\n",
      "Utilize NN output [[ 0.11357308  0.01649823]]\n",
      ">>>>>Step 52 at [  2.29979078e+01  -5.35210425e-01   1.02800450e+01   1.03227686e-02]\n",
      "Utilize NN output [[ 0.10876606  0.01539325]]\n",
      ">>>>>Step 53 at [  2.35120180e+01  -5.29903195e-01   1.02854620e+01   1.82343077e-02]\n",
      "Utilize NN output [[ 0.19873801  0.03405694]]\n",
      ">>>>>Step 54 at [ 24.02645081  -0.52052183  10.29527007   0.03574211]\n",
      "Utilize NN output [[ 0.18865262  0.02439107]]\n",
      ">>>>>Step 55 at [ 24.54111845  -0.50211869  10.30459237   0.04829525]\n",
      "Utilize NN output [[ 0.17891525  0.01639283]]\n",
      ">>>>>Step 56 at [ 25.05596835  -0.47723453  10.31344389   0.05674057]\n",
      "Utilize NN output [[ 0.16959028  0.00999094]]\n",
      ">>>>>Step 57 at [ 25.57102031  -0.44797878  10.32184303   0.06189245]\n",
      "Utilize NN output [[ 0.16070347  0.00504287]]\n",
      ">>>>>Step 58 at [ 26.08632307  -0.41604465  10.32980974   0.06449501]\n",
      "Utilize NN output [[ 0.15986978  0.00125918]]\n",
      ">>>>>Step 59 at [ 26.60193747  -0.3827439   10.33773582   0.06514537]\n",
      "Utilize NN output [[ 0.15987474 -0.00143942]]\n",
      ">>>>>Step 60 at [ 27.11792557  -0.34908204  10.34566214   0.06440135]\n",
      "Utilize NN output [[ 0.15976186 -0.00323098]]\n",
      ">>>>>Step 61 at [ 27.63433394  -0.31577859  10.35358296   0.06273002]\n",
      "Utilize NN output [[ 0.15954648 -0.00430018]]\n",
      ">>>>>Step 62 at [ 28.15119224  -0.28331346  10.36149327   0.06050392]\n",
      "Utilize NN output [[ 0.15924498 -0.00481334]]\n",
      ">>>>>Step 63 at [ 28.66851596  -0.25197509  10.3693889    0.05801028]\n",
      "Utilize NN output [[ 0.15887091 -0.00491666]]\n",
      ">>>>>Step 64 at [ 29.18630988  -0.22190399  10.37726628   0.05546116]\n",
      "Utilize NN output [[ 0.15843084 -0.00473061]]\n",
      ">>>>>Step 65 at [ 29.70457149  -0.19313109  10.3851222    0.05300664]\n",
      "Utilize NN output [[ 0.15793343 -0.00435689]]\n",
      ">>>>>Step 66 at [ 30.22329381  -0.16560958  10.39295386   0.05074431]\n",
      "Utilize NN output [[ 0.15738221 -0.00387351]]\n",
      ">>>>>Step 67 at [ 30.74246748  -0.13924184  10.40075864   0.04873146]\n",
      "Utilize NN output [[ 0.15678391 -0.00334294]]\n",
      ">>>>>Step 68 at [ 31.26208221  -0.11390019  10.40853423   0.04699301]\n",
      "Utilize NN output [[ 0.15613559 -0.00280752]]\n",
      ">>>>>Step 69 at [ 31.78212777  -0.08944368  10.41627818   0.04553191]\n",
      "Utilize NN output [[ 0.15544133 -0.00229919]]\n",
      ">>>>>Step 70 at [ 32.30259446  -0.06572945  10.42398825   0.04433446]\n",
      "Utilize NN output [[ 0.15470247 -0.00183701]]\n",
      ">>>>>Step 71 at [ 32.8234734   -0.04262142  10.43166225   0.04337701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilize NN output [[ 0.15391612 -0.0014334 ]]\n",
      ">>>>>Step 72 at [  3.33447566e+01  -1.99955189e-02   1.04392979e+01   4.26293729e-02]\n",
      "Utilize NN output [[ 0.15308657 -0.00109151]]\n",
      ">>>>>Step 73 at [  3.38664370e+01   2.25687027e-03   1.04468929e+01   4.20596434e-02]\n",
      "Utilize NN output [[ 0.15221012 -0.00081143]]\n",
      ">>>>>Step 74 at [  3.43885083e+01   2.42279618e-02   1.04544452e+01   4.16357986e-02]\n",
      "Utilize NN output [[ 0.15128952 -0.00058883]]\n",
      ">>>>>Step 75 at [ 34.9109651    0.04599345  10.46195251   0.041328  ]\n",
      "Utilize NN output [[ 0.15032528 -0.00041825]]\n",
      ">>>>>Step 76 at [ 35.43380241   0.06761358  10.46941266   0.04110922]\n",
      "Utilize NN output [[ 0.14931808 -0.0002957 ]]\n",
      ">>>>>Step 77 at [ 35.9570159    0.0891346   10.47682357   0.04095443]\n",
      "Utilize NN output [[ 0.14826643 -0.0002088 ]]\n",
      ">>>>>Step 78 at [ 36.48060166   0.11058975  10.48418304   0.04084505]\n",
      "Utilize NN output [[ 0.14717625 -0.00015256]]\n",
      ">>>>>Step 79 at [ 37.0045561    0.13200261  10.49148918   0.04076508]\n",
      "Utilize NN output [[ 0.27533984  0.02128584]]\n",
      ">>>>>Step 80 at [ 37.5290302    0.15339469  10.50491851   0.0519294 ]\n",
      "Utilize NN output [[ 0.26949313  0.012955  ]]\n",
      ">>>>>Step 81 at [ 38.05389658   0.18067521  10.51807616   0.05873358]\n",
      "Utilize NN output [[ 0.26347467  0.00650042]]\n",
      ">>>>>Step 82 at [ 38.57921494   0.21156457  10.53095329   0.06215213]\n",
      "Utilize NN output [[ 0.2573801   0.00171023]]\n",
      ">>>>>Step 83 at [ 39.10506013   0.24428911  10.54354546   0.06305265]\n",
      "Utilize NN output [[ 0.25134358 -0.00140127]]\n",
      ">>>>>Step 84 at [ 39.63149693   0.27752641  10.55585453   0.06231393]\n",
      "Utilize NN output [[ 0.24535049 -0.00344165]]\n",
      ">>>>>Step 85 at [ 40.15856537   0.31041269  10.56788168   0.06049746]\n",
      "Utilize NN output [[ 0.23943387 -0.00463724]]\n",
      ">>>>>Step 86 at [ 40.68628596   0.34237745  10.57962973   0.05804719]\n",
      "Utilize NN output [[ 0.23361534 -0.00519453]]\n",
      ">>>>>Step 87 at [ 41.21466284   0.37308274  10.59110254   0.0552994 ]\n",
      "Utilize NN output [[ 0.21669786 -0.0072258 ]]\n",
      ">>>>>Step 88 at [ 41.74367478   0.40236664  10.60177096   0.05147301]\n",
      "Utilize NN output [[ 0.19538684 -0.009217  ]]\n",
      ">>>>>Step 89 at [ 42.27330211   0.42965225  10.61141785   0.04658732]\n",
      "Utilize NN output [[ 0.17604157 -0.01001027]]\n",
      ">>>>>Step 90 at [  4.28035149e+01   4.54371328e-01   1.06201301e+01   4.12763407e-02]\n",
      "Utilize NN output [[ 0.15852332 -0.00995371]]\n",
      ">>>>>Step 91 at [  4.33342655e+01   4.76291219e-01   1.06279906e+01   3.59910324e-02]\n",
      "Utilize NN output [[ 0.14268033 -0.00871949]]\n",
      ">>>>>Step 92 at [  4.38654979e+01   4.95419083e-01   1.06350765e+01   3.13576160e-02]\n",
      "Utilize NN output [[ 0.12787047 -0.00614609]]\n",
      ">>>>>Step 93 at [  4.43971492e+01   5.12095867e-01   1.06414355e+01   2.80894527e-02]\n",
      "Utilize NN output [[ 0.11421829 -0.00509287]]\n",
      ">>>>>Step 94 at [  4.49291532e+01   5.27043499e-01   1.06471217e+01   2.53797013e-02]\n",
      "Utilize NN output [[ 0.10202105 -0.00409809]]\n",
      ">>>>>Step 95 at [  4.54614649e+01   5.40556312e-01   1.06522051e+01   2.31980679e-02]\n",
      "Utilize NN output [[ 0.09113454 -0.00319668]]\n",
      ">>>>>Step 96 at [  4.59940454e+01   5.52913368e-01   1.06567492e+01   2.14954915e-02]\n",
      "Utilize NN output [[ 0.08141842 -0.00240996]]\n",
      ">>>>>Step 97 at [  4.65268613e+01   5.64368271e-01   1.06608112e+01   2.02113770e-02]\n",
      "Utilize NN output [[ 0.14866464  0.02151005]]\n",
      ">>>>>Step 98 at [  4.70599774e+01   5.75144750e-01   1.06681901e+01   3.16753399e-02]\n",
      "Utilize NN output [[ 0.13269876  0.01285202]]\n",
      ">>>>>Step 99 at [  4.75932842e+01   5.92043075e-01   1.06747864e+01   3.85303524e-02]\n",
      "Utilize NN output [[ 0.11843222  0.00643864]]\n",
      ">>>>>Step 100 at [  4.81267746e+01   6.12608827e-01   1.06806805e+01   4.19668620e-02]\n",
      "Utilize NN output [[ 0.10571015  0.00202185]]\n",
      ">>>>>Step 101 at [  4.86604699e+01   6.35019504e-01   1.06859464e+01   4.30465953e-02]\n",
      "Utilize NN output [[ 0.09434059 -0.00105235]]\n",
      ">>>>>Step 102 at [  4.91943898e+01   6.58017142e-01   1.06906495e+01   4.24843280e-02]\n",
      "Utilize NN output [[ 0.08418044 -0.00306772]]\n",
      ">>>>>Step 103 at [  4.97285448e+01   6.80724023e-01   1.06948486e+01   4.08445359e-02]\n",
      "Utilize NN output [[ 0.07510086 -0.00427372]]\n",
      ">>>>>Step 104 at [  5.02629349e+01   7.02563083e-01   1.06985966e+01   3.85592124e-02]\n",
      "Utilize NN output [[ 0.06698932 -0.00487807]]\n",
      ">>>>>Step 105 at [  5.07975506e+01   7.23187668e-01   1.07019411e+01   3.59498105e-02]\n",
      "Utilize NN output [[ 0.0599262  -0.00414223]]\n",
      ">>>>>Step 106 at [  5.13323767e+01   7.42422851e-01   1.07049338e+01   3.37333277e-02]\n",
      "Utilize NN output [[ 0.05360562 -0.00346102]]\n",
      ">>>>>Step 107 at [  5.18673858e+01   7.60477337e-01   1.07076115e+01   3.18808359e-02]\n",
      "Utilize NN output [[ 0.04795036 -0.00286036]]\n",
      ">>>>>Step 108 at [  5.24025542e+01   7.77544735e-01   1.07100072e+01   3.03494593e-02]\n",
      "Utilize NN output [[ 0.04286752 -0.00309389]]\n",
      ">>>>>Step 109 at [  5.29378615e+01   7.93796012e-01   1.07121492e+01   2.86926861e-02]\n",
      "Utilize NN output [[ 0.03824933 -0.00573527]]\n",
      ">>>>>Step 110 at [  5.34732962e+01   8.09163291e-01   1.07140608e+01   2.56208638e-02]\n",
      "Utilize NN output [[ 0.03412208 -0.00716525]]\n",
      ">>>>>Step 111 at [  5.40088661e+01   8.22888056e-01   1.07157662e+01   2.17824834e-02]\n",
      "Utilize NN output [[ 0.06387065  0.00281974]]\n",
      ">>>>>Step 112 at [  5.45446070e+01   8.34559670e-01   1.07189554e+01   2.32932627e-02]\n",
      "Utilize NN output [[ 0.0568376  -0.00175589]]\n",
      ">>>>>Step 113 at [  5.50804803e+01   8.47044166e-01   1.07217942e+01   2.23521976e-02]\n",
      "Utilize NN output [[ 0.05057231 -0.00465652]]\n",
      ">>>>>Step 114 at [  5.56164993e+01   8.59027363e-01   1.07243207e+01   1.98559033e-02]\n",
      "Utilize NN output [[ 0.04498723 -0.00633702]]\n",
      ">>>>>Step 115 at [  5.61526658e+01   8.69674833e-01   1.07265685e+01   1.64579363e-02]\n",
      "iteration 0 accepted [  9.86075929e-26] [  7.20477814e+01  -3.72331544e-03   1.06390794e+01  -1.06989090e-01] [-2.06543994 -0.20227802]\n",
      "Utilize NN output [[ 0.04000774 -0.00715983]]\n",
      ">>>>>Step 116 at [  5.66889716e+01   8.78502116e-01   1.07285679e+01   1.26179837e-02]\n",
      "iteration 0 accepted [  7.97952359e-16] [  7.25691465e+01  -1.24549849e-02   1.05874081e+01  -1.16921093e-01] [-64.52526093  -0.20614915]\n",
      "Utilize NN output [[ 0.03556677 -0.00739942]]\n",
      ">>>>>Step 117 at [  5.72254017e+01   8.85271142e-01   1.07303455e+01   8.64879505e-03]\n",
      "iteration 0 accepted [  2.89146279e+18] [ 73.2905573    0.2410211   10.70388633  -0.11650017] [  5.73241211e+02  -4.21062261e-01]\n",
      "Utilize MPC output [ 0.07144368 -0.00838287]\n",
      ">>>>>Step 118 at [  5.77619880e+01   8.89912083e-01   1.07339116e+01   4.15134841e-03]\n",
      "iteration 0 accepted [  4.76993164e+15] [ 72.54708876  -0.10075627  10.62385843  -0.27753743] [ -2.03409863e+03   1.01192224e+00]\n",
      "Utilize MPC output [ 0.75929034 -0.29395035]\n",
      ">>>>>Step 119 at [ 58.29947982   0.89214341  10.76594451  -0.14921835]\n",
      "iteration 0 failed 1.59604002945e+36 [ 74.42469529   0.11516728  10.78110827  -0.15606751] [ 0.0017698 -0.0241556]\n",
      "Utilize MPC output [ 0.01957483  0.07665919]\n",
      ">>>>>Step 120 at [ 58.83181945   0.8121137   10.76692313  -0.10803356]\n",
      "iteration 0 failed 8.41131284753e+43 [  7.49558394e+01   3.16369887e-02   1.07810917e+01  -1.70101693e-01] [ 0.00148507 -0.02601451]\n",
      "Utilize MPC output [ 0.01740225  0.06123887]\n",
      ">>>>>Step 121 at [ 59.3670487    0.75406497  10.76779315  -0.075107  ]\n",
      "iteration 0 failed 1.34189337139e+54 [  7.54863291e+01  -5.94314493e-02   1.07810595e+01  -1.85241916e-01] [ 0.00123947 -0.02807168]\n",
      "Utilize MPC output [ 0.0154328   0.04785527]\n",
      ">>>>>Step 122 at [  5.99039398e+01   7.13664696e-01   1.07685647e+01  -4.93618699e-02]\n",
      "iteration 0 failed 3.27207630286e+65 [ 76.0157855   -0.15858835  10.78101912  -0.20160829] [ 0.00102896 -0.03034866]\n",
      "Utilize MPC output [ 0.01366673  0.03639053]\n",
      ">>>>>Step 123 at [  6.04417292e+01   6.87096821e-01   1.07692480e+01  -2.97768246e-02]\n",
      "iteration 0 accepted [  1.05793919e-11] [ 68.37428895   0.23821533  11.71993096   5.00618503] [  1.42101367e+04  -1.08344727e+01]\n",
      "Utilize NN output [[ 0.01365961  0.04551819]]\n",
      ">>>>>Step 124 at [  6.09799700e+01   6.71064981e-01   1.07699310e+01  -5.28390623e-03]\n",
      "iteration 0 accepted [  1.00741285e+65] [ 61.18369214   1.98453074   9.92053553  -1.7244982 ] [  4.25133838e+03   3.62760496e+00]\n",
      "Utilize MPC output [ 787.15362549 -599.78265381]\n",
      ">>>>>Step 125 at [ 61.51970901   0.66821302  10.81993096  -0.54378045]\n",
      "iteration 0 accepted [  3.08721077e-08] [ 63.61309177  -0.63039291   9.57084865  -0.40304047] [ -2.29241162e+03   8.05135965e-01]\n",
      "Utilize NN output [[ 0.01835567  0.4215118 ]]\n",
      ">>>>>Step 126 at [ 61.98269125   0.38830315  10.82084865  -0.32835386]\n",
      "iteration 0 accepted [  3.60616897e+54] [ 67.82752482  -2.0023117    9.77127545  -4.12702121] [ -1.19295352e+04   7.96536541e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilize MPC output [-2666.57055664  -127.11344147]\n",
      ">>>>>Step 127 at [ 62.49364499   0.21422805  10.77084865  -0.86939629]\n",
      "iteration 0 failed 9.40057243668e+116 [ 78.15952496  -0.7151641   10.77879675  -0.33525127] [ 0.00122841 -0.06221667]\n",
      "Utilize MPC output [-18515392.         -155692.515625]\n",
      ">>>>>Step 128 at [ 62.84035328  -0.19623087  10.72084865  -1.40793872]\n",
      "iteration 0 accepted [  1.38360110e+78] [ 70.7845891   -2.22145539  10.07266386   0.56984586] [ -4.65508643e+03  -2.56318808e+00]\n",
      "Utilize MPC output [ 1144.73413086    -7.15813923]\n",
      ">>>>>Step 129 at [ 62.92746915  -0.72641384  10.77084865  -1.9439805 ]\n",
      "iteration 0 failed 5.65115742744e+78 [ 76.57105808  -0.26153999  10.78569157  -0.24039734] [ 0.00158449 -0.05333202]\n",
      "Utilize MPC output [ 0.05505087  0.99643439]\n",
      ">>>>>Step 130 at [ 62.73110106  -1.22795304  10.77359841  -1.53463837]\n",
      "iteration 0 accepted [  6.58279707e+79] [ 67.81291436   2.32670273  11.72635166   7.08207351] [  1.93456914e+04  -1.47630234e+01]\n",
      "Utilize MPC output [  1.29345772e+10   2.69264384e+08]\n",
      ">>>>>Step 131 at [ 62.75061956  -1.76753005  10.82359841  -0.99595845]\n",
      "iteration 0 accepted [  1.38279759e+89] [ 75.56735049   0.1007379   10.85634974  -0.29145733] [  2.14255054e+03  -5.14109284e-02]\n",
      "Utilize MPC output [  -117.69071198 -10558.50292969]\n",
      ">>>>>Step 132 at [ 63.04417877  -2.22068268  10.77359841  -1.53713837]\n",
      "iteration 0 failed 3.67997665209e+94 [ 76.89903614  -0.34670441  10.78897678  -0.23961879] [ 0.00090263 -0.04024968]\n",
      "Utilize MPC output [-173.00848389    8.06843567]\n",
      ">>>>>Step 133 at [ 63.06226415  -2.75780822  10.72359841  -0.99845856]\n",
      "iteration 0 failed 3.65875936982e+103 [ 77.54646949  -0.48706258  10.73599134  -0.30238942] [ 0.00195261 -0.07686494]\n",
      "Utilize MPC output [-47.19070053   0.82868475]\n",
      ">>>>>Step 134 at [ 63.35198152  -3.20749018  10.67359841  -0.63397999]\n",
      "iteration 0 accepted [  1.43558612e+114] [ 69.36298248  -0.22372748  11.57598227  -0.2644346 ] [  8.91131897e+02  -7.08687544e-01]\n",
      "Utilize MPC output [  1.85060967e-02  -6.75420184e+23]\n",
      ">>>>>Step 135 at [ 63.78197343  -3.5236324   10.67452361  -1.16765991]\n",
      "iteration 0 accepted [  4.76953269e+143] [ 76.68995515  -0.17483183  10.72785394  -0.26160668] [  9.16366394e+02  -1.01268083e-01]\n",
      "Utilize MPC output [-47.66069412   0.99318743]\n",
      ">>>>>Step 136 at [ 63.99086663  -4.01342267  10.62452361  -0.76271216]\n",
      "iteration 0 failed 4.94430443607e+143 [ 77.8652373   -0.56164069  10.63897498  -0.29448556] [ 0.00150488 -0.05917218]\n",
      "Utilize MPC output [ 0.02669206  0.97228771]\n",
      ">>>>>Step 137 at [ 64.37494862  -4.3804618   10.6258579   -0.36444771]\n",
      "iteration 0 failed 7.16866100851e+143 [ 78.37046717  -0.71548097  10.63853909  -0.32898006] [ 0.00143752 -0.0648465 ]\n",
      "Utilize MPC output [ 0.01464095  0.85781288]\n",
      ">>>>>Step 138 at [  6.48713637e+01  -4.56983882e+00   1.06265899e+01   4.86944460e-03]\n",
      "iteration 0 failed 1.66849007149e+142 [ 78.87126726  -0.88674199  10.63794128  -0.36596782] [ 0.00137495 -0.06965322]\n",
      "Utilize MPC output [ 0.00980401  0.60163152]\n",
      ">>>>>Step 139 at [ 65.40269915  -4.56725149  10.62708008   0.29083603]\n",
      "iteration 0 failed 2.47056324645e+159 [ 79.3946183   -1.07860896  10.6374408   -0.40473029] [ 0.00124708 -0.07414772]\n",
      "Utilize MPC output [ 0.00925812  0.45847285]\n",
      ">>>>>Step 140 at [ 65.91174975  -4.41488069  10.62754297   0.5187012 ]\n",
      "iteration 0 failed 1.65316038051e+178 [ 79.92198079  -1.29034511  10.63715279  -0.44572883] [ 0.00111131 -0.07865317]\n",
      "Utilize MPC output [ 0.0094726   0.29664528]\n",
      ">>>>>Step 141 at [ 66.37324185  -4.15144321  10.62801659   0.67186514]\n",
      "iteration 0 failed 7.43312330924e+181 [ 80.46229826  -1.52279227  10.63632378  -0.51085415] [ 0.00125647 -0.12507208]\n",
      "Utilize MPC output [ 0.01041208  0.16630602]\n",
      ">>>>>Step 142 at [ 66.78915931  -3.82066635  10.62853717   0.75943446]\n",
      "iteration 0 accepted [  5.74106549e+138] [ 75.99477725  -7.08153909   9.8790541   -1.06895885] [ -1.11684736e+04   2.09103441e+00]\n",
      "Utilize MPC output [  3153.96728516  14825.60058594]\n",
      ">>>>>Step 143 at [ 67.17547016  -3.45391225  10.67853717   1.29086131]\n",
      "iteration 0 accepted [  3.14379350e+21] [ 74.28960782  -1.93418759  10.61948765  -0.2549099 ] [ -3.47185474e+03  -1.10989010e+00]\n",
      "Utilize MPC output [ 106904.7890625      647.85150146]\n",
      ">>>>>Step 144 at [ 67.32333588  -2.93956801  10.72853717   1.82478817]\n",
      "iteration 0 failed 3.32803851875e+177 [ 80.89861305  -1.81381584  10.73448361  -0.4602803 ] [ 0.00076415  0.08810271]\n",
      "Utilize MPC output [ 0.00932832 -0.55003583]\n",
      ">>>>>Step 145 at [ 67.18854512  -2.42033999  10.72900357   1.55628128]\n",
      "iteration 0 failed 2.67682991121e+173 [ 81.30945754  -2.04890922  10.73445174  -0.40567674] [ 0.0008422   0.10415537]\n",
      "Utilize MPC output [ 0.00922834 -0.49189132]\n",
      ">>>>>Step 146 at [ 67.19633162  -1.88393479  10.72946498   1.31181221]\n",
      "iteration 0 failed 7.0039817423e+170 [ 81.75764491  -2.25890771  10.73462381  -0.34814813] [ 0.00087391  0.10876551]\n",
      "Utilize MPC output [ 0.00737616 -0.43715444]\n",
      ">>>>>Step 147 at [ 67.33372407  -1.36534367  10.72983378   1.09116989]\n",
      "iteration 0 failed 6.32595677577e+168 [ 82.22541359  -2.44067592  10.73465548  -0.29210099] [ 0.00088321  0.10571202]\n",
      "Utilize MPC output [ 0.01054995 -0.38617477]\n",
      ">>>>>Step 148 at [ 67.58129306  -0.88937405  10.73036126   0.89370991]\n",
      "iteration 0 failed 2.73698939051e+167 [ 82.70844052  -2.59427533  10.73489938  -0.2401905 ] [ 0.00087423  0.09773419]\n",
      "Utilize MPC output [ -9.00520845e+17   7.83701716e+15]\n",
      ">>>>>Step 149 at [ 67.9166518   -0.47218534  10.68036126   1.43022797]\n",
      "iteration 0 failed 1.8931034239e+175 [ 82.3144471   -2.43678374  10.68645111  -0.29285422] [ 0.00090414  0.10598319]\n",
      "Utilize MPC output [  9.06123939e+16  -1.76231689e+15]\n",
      ">>>>>Step 150 at [  6.79916460e+01   5.78031158e-02   1.07303613e+01   8.96209909e-01]\n",
      "iteration 0 failed 5.37635337004e+167 [ 83.08644323  -2.72011937  10.73476845  -0.1939304 ] [ 0.00107073  0.08736877]\n",
      "Utilize MPC output [ 0.00704574 -0.45936257]\n",
      ">>>>>Step 151 at [ 68.32674694   0.476812    10.73071354   0.66574077]\n",
      "iteration 0 failed 2.17056868786e+168 [ 83.57826685  -2.82209286  10.73487514  -0.15454872] [ 0.00106043  0.07536189]\n",
      "Utilize MPC output [ 0.00740974 -0.39044747]\n",
      ">>>>>Step 152 at [ 68.74871779   0.80820463  10.73108402   0.46628582]\n",
      "iteration 0 failed 6.99152944231e+168 [ 84.08118034  -2.90234787  10.73486215  -0.12148564] [ 0.00103652  0.06261405]\n",
      "iteration 0 failed 4.82491908496e+295 [  8.40999820e+01   6.23867928e-02   1.07344906e+01   8.99962844e-02] [ 0.00103652  0.06261405]\n",
      "Utilize MPC output [ 0.00709651 -0.32338879]\n",
      ">>>>>Step 153 at [ 69.22799966   1.04942822  10.73143884   0.29857623]\n",
      "iteration 0 failed 9.22343394196e+168 [ 84.59223424  -2.96632019  10.73488655  -0.09434193] [ 0.00100314  0.05049463]\n",
      "iteration 0 failed 1.74087361619e+271 [ 84.58922045  -0.36483548  10.7345306    0.08780119] [ 0.00100314  0.05049463]\n",
      "iteration 0 failed 1.74087361619e+271 [ 84.58922045  -0.36483548  10.7345306    0.08780119] [ 0.00100314  0.05049463]\n",
      "iteration 0 failed 1.74087361619e+271 [ 84.58922045  -0.36483548  10.7345306    0.08780119] [ 0.00100314  0.05049463]\n",
      "iteration 0 failed 1.74087361619e+271 [ 84.58922045  -0.36483548  10.7345306    0.08780119] [ 0.00100314  0.05049463]\n",
      "iteration 0 failed 1.74087361619e+271 [ 84.58922045  -0.36483548  10.7345306    0.08780119] [ 0.00100314  0.05049463]\n",
      "Utilize MPC output [ 0.00639698 -0.26352069]\n",
      ">>>>>Step 154 at [ 69.7408393    1.20726842  10.73175868   0.16036302]\n",
      "iteration 0 accepted [  2.29612170e+45] [ 78.42453963  -7.02555532   9.58207957  -0.41153461] [ -3.54841914e+04   1.43802571e+00]\n",
      "Utilize MPC output [ -5.15252539e+03  -2.41014647e+00]\n",
      ">>>>>Step 155 at [ 70.26930852   1.29274936  10.68175868  -0.3676396 ]\n",
      "iteration 0 failed 6.36272075005e+171 [  8.55952534e+01  -3.04371836e+00   1.06852074e+01  -6.02643956e-02] [ 0.00121547  0.0319472 ]\n",
      "iteration 0 failed 2.26147620024e+130 [ 84.91016707  -3.46789512  10.6848802   -0.10209082] [ 0.00121547  0.0319472 ]\n",
      "Utilize MPC output [ -3.11593166e+14  -3.35392309e+33]\n",
      ">>>>>Step 156 at [ 70.76654132   1.10124007  10.63175868  -0.90172753]\n",
      "iteration 0 failed 9.28298516826e+166 [  8.58800965e+01  -3.04396355e+00   1.06359241e+01  -6.01088121e-02] [ 0.00085543  0.03112583]\n",
      "Utilize MPC output [ 0.00823499  0.38170546]\n",
      ">>>>>Step 157 at [ 71.09626821   0.68425464  10.63217042  -0.70812977]\n",
      "iteration 0 failed 2.05860242618e+166 [  8.63919253e+01  -3.07523784e+00   1.06359908e+01  -4.77707193e-02] [ 0.00083788  0.023405  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilize MPC output [ 0.00868279  0.31443411]\n",
      ">>>>>Step 158 at [ 71.50007545   0.33848178  10.63260455  -0.54627328]\n",
      "iteration 0 failed 1.49991429472e+166 [  8.69103988e+01  -3.10010841e+00   1.06359894e+01  -3.88303049e-02] [ 0.00081291  0.01701831]\n",
      "Utilize MPC output [ 0.00406294  0.2592417 ]\n",
      ">>>>>Step 159 at [  7.19543400e+01   6.22937932e-02   1.06328077e+01  -4.11459223e-01]\n",
      "iteration 0 failed 7.61766293773e+165 [  8.74372354e+01  -3.12034153e+00   1.06358400e+01  -3.26298195e-02] [ 0.0007783   0.01185365]\n",
      "Utilize MPC output [ 0.00374219  0.20103396]\n",
      ">>>>>Step 160 at [ 72.44161302  -0.15033615  10.6329948   -0.30599836]\n",
      "iteration 0 failed 2.87560207043e+165 [  8.79692472e+01  -3.13740396e+00   1.06358779e+01  -2.85829669e-02] [ 0.00073841  0.00781613]\n",
      "Utilize MPC output [ 0.00332432  0.15240514]\n",
      ">>>>>Step 161 at [ 72.94856983  -0.31049439  10.63316102  -0.22559377]\n",
      "iteration 0 failed 1.38501654427e+165 [  8.85024837e+01  -3.15243521e+00   1.06357709e+01  -2.61425627e-02] [ 0.00070011  0.00475644]\n",
      "Utilize MPC output [ 0.00288895  0.11084759]\n",
      ">>>>>Step 162 at [ 73.46675996  -0.4294192   10.63330547  -0.16690095]\n",
      "iteration 0 failed 3.33685076159e+164 [  8.90402018e+01  -3.16622598e+00   1.06358262e+01  -2.53845205e-02] [ 0.0017552   0.00161716]\n",
      "Utilize MPC output [ 0.00247505  0.07580595]\n",
      ">>>>>Step 163 at [ 73.99104044  -0.51774376  10.63342922  -0.12667458]\n",
      "iteration 0 failed 6.66254050833e+163 [  8.95787115e+01  -3.17965979e+00   1.06358721e+01  -2.52715077e-02] [ 0.00164799  0.00038293]\n",
      "Utilize MPC output [ 0.00425207  0.02923582]\n",
      ">>>>>Step 164 at [ 74.51845716  -0.58491371  10.63364182  -0.11113515]\n",
      "iteration 0 failed 6.45168206167e+162 [  9.01191675e+01  -3.19305569e+00   1.06360396e+01  -4.59343162e-02] [ 0.00202254 -0.03867118]\n",
      "Utilize MPC output [ -8.66807304e+18  -7.59082588e+15]\n",
      ">>>>>Step 165 at [ 75.04561693  -0.64374209  10.58364182  -0.64281724]\n",
      "iteration 0 failed 5.71654322479e+147 [  9.05534606e+01  -3.19567857e+00   1.05862415e+01   5.04101920e-02] [ 0.00247898  0.14602764]\n",
      "Utilize MPC output [ 0.00202672  0.32751924]\n",
      ">>>>>Step 166 at [ 75.46918166  -0.96096328  10.58374316  -0.47544227]\n",
      "iteration 0 failed 2.78880907225e+147 [ 91.07473469  -3.1688547   10.58622406   0.12971147] [ 0.00232151  0.15115516]\n",
      "Utilize MPC output [ 1041.74633789    -2.86769247]\n",
      ">>>>>Step 167 at [ 75.94078823  -1.20376118  10.63374316  -1.00122227]\n",
      "iteration 0 failed 4.2623203345e+109 [ 91.41931607  -3.1958899   10.63550387   0.12214041] [ 0.00097083  0.16352385]\n",
      "Utilize MPC output [ 0.00179239  0.54261291]\n",
      ">>>>>Step 168 at [ 76.22751418  -1.65151318  10.63383278  -0.73805664]\n",
      "iteration 0 failed 7.8911487723e+106 [ 91.92532649  -3.13011241  10.63557605   0.20073339] [ 0.00094985  0.14933985]\n",
      "Utilize MPC output [ 0.00182872  0.43122911]\n",
      ">>>>>Step 169 at [ 76.62084941  -2.00926424  10.63392421  -0.52200481]\n",
      "iteration 0 failed 1.90419644495e+103 [ 92.43111166  -3.02329954  10.63566543   0.2673648 ] [ 0.00094609  0.12635039]\n",
      "Utilize MPC output [ 0.00165746  0.32181785]\n",
      ">>>>>Step 170 at [ 77.0817368   -2.27437909  10.63400709  -0.3565677 ]\n",
      "iteration 0 failed 8.01647286779e+98 [ 92.93536861  -2.88209016  10.63567048   0.31975458] [ 0.00096242  0.09935303]\n",
      "Utilize MPC output [ 0.00140062  0.22425456]\n",
      ">>>>>Step 171 at [ 77.57999506  -2.45997496  10.63407712  -0.23929086]\n",
      "iteration 0 failed 1.47391487406e+94 [ 93.43648404  -2.71440269  10.63570956   0.3576417 ] [ 0.00100183  0.07178167]\n",
      "Utilize MPC output [ 0.00113705  0.1428692 ]\n",
      ">>>>>Step 172 at [ 78.09655009  -2.58599642  10.63413397  -0.16383942]\n",
      "iteration 0 failed 3.92235093043e+89 [ 93.93301707  -2.52778233  10.63574471   0.38186242] [ 0.00106865  0.04596125]\n",
      "Utilize MPC output [ 0.00096981  0.07268442]\n",
      ">>>>>Step 173 at [ 78.62113754  -2.67272192  10.63418246  -0.12526054]\n",
      "iteration 0 failed 3.32216190771e+85 [ 94.42456829  -2.32917003  10.6357904    0.39400668] [ 0.00116624  0.02320204]\n",
      "Utilize MPC output [ 0.00093448  0.01018128]\n",
      ">>>>>Step 174 at [ 79.14868196  -2.7391502   10.63422918  -0.11984724]\n",
      "iteration 0 failed 2.07334931232e+82 [ 94.91186098  -2.12455286  10.63585491   0.39598812] [ 0.00129637  0.00406296]\n",
      "Utilize MPC output [ 0.00117863 -0.0775283 ]\n",
      ">>>>>Step 175 at [ 79.67658087  -2.80272209  10.63428811  -0.16098753]\n",
      "iteration 0 failed 7.7959716372e+79 [ 95.39426597  -1.91876251  10.63595262   0.38971727] [ 0.00146514 -0.01137771]\n",
      "Utilize MPC output [ 0.00099977  0.11582019]\n",
      ">>>>>Step 176 at [ 80.20142116  -2.88795242  10.6343381   -0.09967817]\n",
      "iteration 0 failed 2.90183311099e+76 [ 95.8931567   -1.71737963  10.6360163    0.37748208] [ 0.00160981 -0.02345105]\n",
      "Utilize MPC output [ 0.00095213  0.04245972]\n",
      ">>>>>Step 177 at [  8.07304999e+01  -2.94086538e+00   1.06343857e+01  -7.71151706e-02]\n",
      "iteration 0 accepted [  6.48431243e+73] [  7.84766851e+01  -6.03123088e+00   1.03770338e+01  -3.71373030e-02] [ 15.23169804   1.64990675]\n",
      "Utilize MPC output [-20044.9921875   -2575.42114258]\n",
      ">>>>>Step 178 at [ 81.25939272  -2.98173207  10.58438571  -0.60883446]\n",
      "iteration 0 failed 2.02509789635e+60 [ 96.64374365  -1.32645653  10.5869008    0.33983662] [ 0.00384015 -0.03801239]\n",
      "Utilize MPC output [ 0.00105795  0.346939  ]\n",
      ">>>>>Step 179 at [ 81.69352041  -3.28439955  10.58443861  -0.43225615]\n",
      "iteration 0 accepted [  6.18986950e+39] [ 84.86332224  -4.74663052  10.66542727   0.2512012 ] [ 5.78771544  0.78257239]\n",
      "Utilize MPC output [ -1.20938838e+04  -1.19796002e+00]\n",
      ">>>>>Step 180 at [ 82.17293102  -3.50557782  10.53443861  -0.87311459]\n",
      "iteration 0 accepted [  2.65107462e+49] [ 91.29938392  -5.66098092  10.58926027   0.42864676] [ 3.46443605 -0.95448285]\n",
      "Utilize MPC output [-1.26096082  0.55853486]\n",
      ">>>>>Step 181 at [ 82.51063609  -3.90840703  10.49187217  -0.60612475]\n",
      "iteration 0 failed 2.50967942827e+53 [ 97.60715077  -0.98325542  10.49620924   0.29601609] [ 0.00708259 -0.0440724 ]\n",
      "Utilize MPC output [ 0.0006486   0.46858156]\n",
      ">>>>>Step 182 at [ 82.94178024  -4.20726156  10.4919046   -0.37684979]\n",
      "iteration 0 accepted [  2.07915491e+48] [ 83.81340143  -5.39378372  10.569585     0.26311133] [ 7.02270222  0.39433682]\n",
      "Utilize MPC output [-7006.5546875   -179.99163818]\n",
      ">>>>>Step 183 at [ 83.42840155  -4.39984902  10.4419046   -0.90144502]\n",
      "iteration 0 failed 1.49411797775e+36 [ 98.03502553  -0.82361593  10.44754298   0.27220679] [ 0.01076013 -0.04497707]\n",
      "Utilize NN output [[ 0.00090566  0.84778666]]\n",
      ">>>>>Step 184 at [ 83.75235054  -4.80928969  10.44194988  -0.54124557]\n",
      "iteration 0 failed 1.49411797775e+36 [ 98.53818259  -0.68316698  10.44811914   0.24890629] [ 0.01152359 -0.04463438]\n",
      "Utilize NN output [[ 0.00086983  0.6613574 ]]\n",
      ">>>>>Step 185 at [ 84.19982433  -5.07827692  10.44199337  -0.23881221]\n",
      "iteration 0 failed 1.49411797775e+36 [ 99.04450405  -0.5544716   10.44872928   0.22620601] [ 0.01220352 -0.04348071]\n",
      "Utilize NN output [[ 0.00090005  0.54670423]]\n",
      ">>>>>Step 186 at [  8.47071077e+01  -5.20177920e+00   1.04420384e+01   2.12174533e-02]\n",
      "iteration 0 failed 1.49411797775e+36 [ 99.55364667  -0.43729502  10.44936854   0.20442466] [ 0.01278579 -0.04171605]\n",
      "Utilize NN output [[ 0.00088355  0.40844199]]\n",
      ">>>>>Step 187 at [ 85.22909322  -5.19070233  10.44208255   0.22334868]\n",
      "iteration 0 failed 1.49411797775e+36 [ 100.06525246   -0.33122856   10.45003169    0.1837843 ] [ 0.01326376 -0.03952603]\n",
      "Utilize NN output [[ 0.00089108  0.26371214]]\n",
      ">>>>>Step 188 at [ 85.73822999  -5.07505792  10.44212711   0.35792851]\n",
      "iteration 0 failed 1.49411797775e+36 [ 100.57897143   -0.23573753   10.45071346    0.16442857] [ 0.01363632 -0.03706131]\n",
      "Utilize NN output [[ 0.00095866  0.13598242]]\n",
      ">>>>>Step 189 at [ 86.22724874  -4.89214549  10.44217504   0.4284914 ]\n",
      "iteration 0 failed 1.49411797775e+36 [ 101.09447632   -0.15020153   10.45140875    0.14643518] [ 0.0139066  -0.03444837]\n",
      "Utilize NN output [[ 0.00109673  0.03920408]]\n",
      ">>>>>Step 190 at [ 86.70215677  -4.67520922  10.44222988   0.44894971]\n",
      "iteration 0 failed 1.49411797775e+36 [  1.01611471e+02  -7.39494531e-02   1.04521128e+01   1.29833642e-01] [ 0.01408103 -0.0317797 ]\n",
      "Utilize MPC output [-3407.39111328  -170.80773926]\n",
      ">>>>>Step 191 at [  8.71714027e+01  -4.44914514e+00   1.03922299e+01  -7.31617857e-02]\n",
      "Utilize NN output [[ 0.00178447  0.31880009]]\n",
      ">>>>>Step 192 at [  8.76896264e+01  -4.48712711e+00   1.03923191e+01   8.70975992e-02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilize NN output [[ 0.00176083  0.20684601]]\n",
      ">>>>>Step 193 at [ 88.20727487  -4.44192681  10.39240714   0.19307101]\n",
      "Utilize NN output [[ 0.00179524  0.11349511]]\n",
      ">>>>>Step 194 at [ 88.71724268  -4.34222487  10.3924969    0.25179346]\n",
      "Utilize NN output [[ 0.00189332  0.04331294]]\n",
      ">>>>>Step 195 at [ 89.22048457  -4.21276429  10.39259157   0.27428588]\n",
      "Utilize NN output [[ 0.00204094 -0.00537429]]\n",
      ">>>>>Step 196 at [ 89.72069226  -4.07201695  10.39269362   0.27149327]\n",
      "Utilize NN output [[ 0.00290872 -0.07488175]]\n",
      ">>>>>Step 197 at [ 90.22129702  -3.93266538  10.39283905   0.23265468]\n",
      "Utilize NN output [[ 0.00273129  0.1082461 ]]\n",
      ">>>>>Step 198 at [ 90.72694198  -3.81285518  10.39297562   0.28868522]\n",
      "Utilize NN output [[ 0.00279946  0.10112922]]\n",
      ">>>>>Step 199 at [ 91.22509053  -3.66491428  10.39311559   0.34105847]\n",
      "Utilize NN output [[ 0.0029586  0.0856256]]\n",
      ">>>>>Step 200 at [ 91.71481822  -3.49109609  10.39326352   0.38544588]\n",
      "Utilize NN output [[ 0.00322325  0.06594785]]\n",
      ">>>>>Step 201 at [ 92.1963579   -3.29571559  10.39342468   0.41966696]\n",
      "Utilize NN output [[ 0.00360863  0.04508159]]\n",
      ">>>>>Step 202 at [ 92.67093862  -3.08397042  10.39360511   0.4430787 ]\n",
      "Utilize NN output [[ 0.0041305   0.02500046]]\n",
      ">>>>>Step 203 at [ 93.14044116  -2.86116938  10.39381164   0.45606824]\n",
      "Utilize NN output [[ 0.00480286  0.00687871]]\n",
      ">>>>>Step 204 at [ 93.60702011  -2.63228377  10.39405178   0.45964299]\n",
      "Utilize NN output [[ 0.0056361  -0.00869833]]\n",
      ">>>>>Step 205 at [ 94.07278957  -2.40172593  10.39433358   0.45512256]\n",
      "Utilize NN output [[ 0.00663346 -0.02154455]]\n",
      ">>>>>Step 206 at [ 94.53961026  -2.17326918  10.39466525   0.44392723]\n",
      "Utilize NN output [[ 0.00778824 -0.0317117 ]]\n",
      ">>>>>Step 207 at [ 95.00897557  -1.9500451   10.39505465   0.42745112]\n",
      "Utilize NN output [[ 0.00908272 -0.0393891 ]]\n",
      ">>>>>Step 208 at [ 95.48197406  -1.73457554  10.39550877   0.40698911]\n",
      "Utilize NN output [[ 0.00403987 -0.07187347]]\n",
      ">>>>>Step 209 at [ 95.95929723  -1.52882243  10.39571077   0.36969524]\n",
      "Utilize NN output [[ 0.00460238 -0.06218122]]\n",
      ">>>>>Step 210 at [ 96.44397013  -1.34100557  10.39594088   0.33741593]\n",
      "Utilize NN output [[ 0.00513661 -0.05490851]]\n",
      ">>>>>Step 211 at [ 96.93446358  -1.16892472  10.39619771   0.3089033 ]\n",
      "Utilize NN output [[ 0.00563716 -0.04937502]]\n",
      ">>>>>Step 212 at [ 97.4296763   -1.01089308  10.39647957   0.28325851]\n",
      "Utilize NN output [[ 0.00609938 -0.04506755]]\n",
      ">>>>>Step 213 at [ 97.92879253  -0.86560754  10.39678453   0.25984717]\n",
      "Utilize NN output [[ 0.00651996 -0.04161126]]\n",
      ">>>>>Step 214 at [ 98.43118824  -0.73204167  10.39711052   0.23822848]\n",
      "Utilize NN output [[ 0.0068961  -0.03873927]]\n",
      ">>>>>Step 215 at [ 98.93637015  -0.60936334  10.39745532   0.21809972]\n",
      "Utilize NN output [[ 0.00722638 -0.03625838]]\n",
      ">>>>>Step 216 at [ 99.44393615  -0.49687404  10.39781664   0.19925823]\n",
      "Utilize NN output [[ 0.0075096 -0.0340355]]\n",
      ">>>>>Step 217 at [ 99.95354945  -0.3939638   10.39819211   0.18157032]\n",
      "Utilize NN output [[ 0.00774587 -0.03198221]]\n",
      ">>>>>Step 218 at [ 100.46492197   -0.30007974   10.3985794     0.16494813]\n",
      "Utilize NN output [[ 0.00793643 -0.0300337 ]]\n",
      ">>>>>Step 219 at [ 100.97780366   -0.21470517   10.39897621    0.14933743]\n",
      "Utilize NN output [[ 0.00808288 -0.02816394]]\n",
      ">>>>>Step 220 at [ 101.49197537   -0.13734413   10.39938034    0.1346975 ]\n",
      "Utilize NN output [[ 0.008188   -0.02634812]]\n",
      ">>>>>Step 221 at [  1.02007245e+02  -6.75158322e-02   1.03997897e+01   1.21000457e-01]\n",
      "Utilize NN output [[ 0.02154733 -0.01678473]]\n",
      ">>>>>Step 222 at [  1.02523459e+02  -4.74703741e-03   1.04008669e+01   1.12273393e-01]\n",
      "Utilize NN output [[ 0.02159392 -0.01901102]]\n",
      ">>>>>Step 223 at [  1.03040255e+02   5.35204303e-02   1.04019465e+01   1.02388027e-01]\n",
      "Utilize NN output [[ 0.0215805  -0.02006872]]\n",
      ">>>>>Step 224 at [  1.03557655e+02   1.06681932e-01   1.04030253e+01   9.19517399e-02]\n",
      "Utilize NN output [[ 0.0215015  -0.02024222]]\n",
      ">>>>>Step 225 at [  1.04075636e+02   1.54445842e-01   1.04041002e+01   8.14241615e-02]\n",
      "Utilize NN output [[ 0.02135686 -0.01976766]]\n",
      ">>>>>Step 226 at [  1.04594144e+02   1.96758482e-01   1.04051679e+01   7.11422655e-02]\n",
      "Utilize NN output [[ 0.0211502  -0.01884348]]\n",
      ">>>>>Step 227 at [  1.05113113e+02   2.33741508e-01   1.04062253e+01   6.13399493e-02]\n",
      "Utilize NN output [[ 0.02088805 -0.01762813]]\n",
      ">>>>>Step 228 at [  1.05632471e+02   2.65638965e-01   1.04072695e+01   5.21687868e-02]\n",
      "Utilize NN output [[ 0.02057647 -0.01624981]]\n",
      ">>>>>Step 229 at [  1.06152153e+02   2.92774725e-01   1.04082982e+01   4.37137256e-02]\n",
      "Utilize NN output [[ 0.0202235 -0.014802 ]]\n",
      ">>>>>Step 230 at [  1.06672096e+02   3.15517859e-01   1.04093092e+01   3.60111064e-02]\n",
      "Utilize NN output [[ 0.01983716 -0.01335825]]\n",
      ">>>>>Step 231 at [  1.07192248e+02   3.34257238e-01   1.04103010e+01   2.90590145e-02]\n",
      "Utilize NN output [[ 0.01942502 -0.01196551]]\n",
      ">>>>>Step 232 at [  1.07712568e+02   3.49381470e-01   1.04112721e+01   2.28310844e-02]\n",
      "Utilize NN output [[ 0.01899217 -0.0106623 ]]\n",
      ">>>>>Step 233 at [  1.08233020e+02   3.61266011e-01   1.04122216e+01   1.72808892e-02]\n",
      "Utilize NN output [[ 0.01854536 -0.00946055]]\n",
      ">>>>>Step 234 at [  1.08753576e+02   3.70262586e-01   1.04131487e+01   1.23557666e-02]\n",
      "Utilize NN output [[ 0.01808887 -0.0083694 ]]\n",
      ">>>>>Step 235 at [  1.09274217e+02   3.76695823e-01   1.04140531e+01   7.99827841e-03]\n",
      "Utilize NN output [[ 0.0176273  -0.00739904]]\n",
      ">>>>>Step 236 at [  1.09794925e+02   3.80860680e-01   1.04149344e+01   4.14565074e-03]\n",
      "Utilize NN output [[ 0.0171638  -0.00654131]]\n",
      ">>>>>Step 237 at [  1.10315688e+02   3.83019596e-01   1.04157925e+01   7.39334646e-04]\n",
      "Utilize NN output [[ 0.01670098 -0.00578781]]\n",
      ">>>>>Step 238 at [  1.10836499e+02   3.83404650e-01   1.04166274e+01  -2.27486543e-03]\n",
      "Utilize NN output [[ 0.01624122 -0.0051301 ]]\n",
      ">>>>>Step 239 at [  1.11357349e+02   3.82219783e-01   1.04174394e+01  -4.94675735e-03]\n",
      "Utilize NN output [[ 0.01578678 -0.00455665]]\n",
      ">>>>>Step 240 at [  1.11878234e+02   3.79643069e-01   1.04182287e+01  -7.32017428e-03]\n",
      "Utilize NN output [[ 0.01533781 -0.00406421]]\n",
      ">>>>>Step 241 at [  1.12399151e+02   3.75829800e-01   1.04189955e+01  -9.43725597e-03]\n",
      "Utilize NN output [[ 0.01489635 -0.00363798]]\n",
      ">>>>>Step 242 at [  1.12920096e+02   3.70913361e-01   1.04197403e+01  -1.13324542e-02]\n",
      "Utilize NN output [[ 0.01446329 -0.00326808]]\n",
      ">>>>>Step 243 at [  1.13441068e+02   3.65009221e-01   1.04204634e+01  -1.30350760e-02]\n",
      "Utilize NN output [[ 0.01403871 -0.00294538]]\n",
      ">>>>>Step 244 at [  1.13962064e+02   3.58217608e-01   1.04211653e+01  -1.45696852e-02]\n",
      "Utilize NN output [[ 0.01362356 -0.00266501]]\n",
      ">>>>>Step 245 at [  1.14483084e+02   3.50625974e-01   1.04218464e+01  -1.59583057e-02]\n",
      "Utilize NN output [[ 0.01321778 -0.00242057]]\n",
      ">>>>>Step 246 at [  1.15004127e+02   3.42310312e-01   1.04225073e+01  -1.72196436e-02]\n",
      "Utilize NN output [[ 0.03347262 -0.00219461]]\n",
      ">>>>>Step 247 at [  1.15525217e+02   3.33336443e-01   1.04241803e+01  -1.83633086e-02]\n",
      "Utilize NN output [[ 0.032353   -0.00209996]]\n",
      ">>>>>Step 248 at [  1.16046378e+02   3.23765116e-01   1.04257974e+01  -1.94578240e-02]\n",
      "Utilize NN output [[ 0.03126607 -0.00198039]]\n",
      ">>>>>Step 249 at [  1.16567608e+02   3.13621830e-01   1.04273602e+01  -2.04901807e-02]\n",
      "Utilize NN output [[ 0.03021037 -0.00185105]]\n",
      ">>>>>Step 250 at [  1.17088905e+02   3.02938879e-01   1.04288702e+01  -2.14552578e-02]\n",
      "Utilize NN output [[ 0.02918805 -0.00170794]]\n",
      ">>>>>Step 251 at [  1.17610265e+02   2.91751250e-01   1.04303292e+01  -2.23458510e-02]\n",
      "Utilize NN output [[ 0.02819752 -0.00157079]]\n",
      ">>>>>Step 252 at [  1.18131686e+02   2.80097703e-01   1.04317387e+01  -2.31650430e-02]\n",
      "Utilize NN output [[ 0.02723757 -0.00143263]]\n",
      ">>>>>Step 253 at [  1.18653167e+02   2.68015411e-01   1.04331003e+01  -2.39122818e-02]\n",
      "Utilize NN output [[ 0.02630762 -0.00130388]]\n",
      ">>>>>Step 254 at [  1.19174706e+02   2.55541852e-01   1.04344153e+01  -2.45924573e-02]\n",
      "Utilize NN output [[ 0.0254076  -0.00118318]]\n",
      ">>>>>Step 255 at [  1.19696301e+02   2.42711969e-01   1.04356854e+01  -2.52097474e-02]\n",
      "Utilize NN output [[ 0.02453654 -0.00107124]]\n",
      ">>>>>Step 256 at [  1.20217950e+02   2.29558540e-01   1.04369120e+01  -2.57687054e-02]\n",
      "Utilize NN output [[ 0.02369434 -0.00096449]]\n",
      ">>>>>Step 257 at [  1.20739652e+02   2.16111979e-01   1.04380965e+01  -2.62720213e-02]\n",
      "Utilize NN output [[ 0.02287992 -0.00087324]]\n",
      ">>>>>Step 258 at [  1.21261405e+02   2.02401311e-01   1.04392403e+01  -2.67277681e-02]\n",
      "Utilize NN output [[ 0.0220923  -0.00078717]]\n",
      ">>>>>Step 259 at [  1.21783208e+02   1.88451354e-01   1.04403448e+01  -2.71386401e-02]\n",
      "Utilize NN output [[ 0.02133137 -0.00071475]]\n",
      ">>>>>Step 260 at [  1.22305060e+02   1.74285532e-01   1.04414112e+01  -2.75117514e-02]\n",
      "Utilize NN output [[ 0.02059542 -0.00064644]]\n",
      ">>>>>Step 261 at [  1.22826959e+02   1.59923560e-01   1.04424408e+01  -2.78492397e-02]\n",
      "Utilize NN output [[ 0.01988436 -0.00058845]]\n",
      ">>>>>Step 262 at [  1.23348903e+02   1.45384046e-01   1.04434349e+01  -2.81564807e-02]\n",
      "Utilize NN output [[ 0.01919764 -0.00053468]]\n",
      ">>>>>Step 263 at [  1.23870892e+02   1.30682794e-01   1.04443946e+01  -2.84356772e-02]\n",
      "Utilize NN output [[ 0.01853472 -0.00048497]]\n",
      ">>>>>Step 264 at [  1.24392924e+02   1.15834465e-01   1.04453213e+01  -2.86889398e-02]\n",
      "Utilize NN output [[ 0.01789462 -0.00044152]]\n",
      ">>>>>Step 265 at [  1.24914997e+02   1.00852619e-01   1.04462159e+01  -2.89195314e-02]\n",
      "Utilize NN output [[ 0.01727543 -0.00040516]]\n",
      ">>>>>Step 266 at [  1.25437111e+02   8.57491165e-02   1.04470796e+01  -2.91311521e-02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilize NN output [[ 0.01667816 -0.00036439]]\n",
      ">>>>>Step 267 at [  1.25959264e+02   7.05338883e-02   1.04479134e+01  -2.93214942e-02]\n",
      "Utilize NN output [[ 0.01610103 -0.00033703]]\n",
      ">>>>>Step 268 at [  1.26481456e+02   5.52180714e-02   1.04487184e+01  -2.94975596e-02]\n",
      "Utilize NN output [[ 0.01554451 -0.0003058 ]]\n",
      ">>>>>Step 269 at [  1.27003684e+02   3.98091484e-02   1.04494956e+01  -2.96573213e-02]\n",
      "Utilize NN output [[ 0.03907377 -0.00104251]]\n",
      ">>>>>Step 270 at [  1.27525977e+02   2.43147698e-02   1.04514483e+01  -3.02020088e-02]\n",
      "Utilize NN output [[ 0.03757028 -0.00074217]]\n",
      ">>>>>Step 271 at [  1.28048358e+02   8.53301500e-03   1.04533259e+01  -3.05898448e-02]\n",
      "Utilize NN output [[ 0.03612514 -0.00051251]]\n",
      ">>>>>Step 272 at [  1.28570825e+02  -7.45415296e-03   1.04551314e+01  -3.08577167e-02]\n",
      "Utilize NN output [[ 0.03473417 -0.0003359 ]]\n",
      ">>>>>Step 273 at [  1.29093376e+02  -2.35840062e-02   1.04568674e+01  -3.10333116e-02]\n",
      "Utilize NN output [[ 0.03339784 -0.00021276]]\n",
      ">>>>>Step 274 at [  1.29616010e+02  -3.98082580e-02   1.04585366e+01  -3.11445512e-02]\n",
      "Utilize NN output [[ 0.03211445 -0.00011781]]\n",
      ">>>>>Step 275 at [  1.30138723e+02  -5.60931963e-02   1.04601418e+01  -3.12061564e-02]\n",
      "Utilize NN output [[  3.08820847e-02  -5.96344471e-05]]\n",
      ">>>>>Step 276 at [  1.30661514e+02  -7.24127926e-02   1.04616854e+01  -3.12373457e-02]\n",
      "Utilize NN output [[  2.96976250e-02  -2.41100788e-05]]\n",
      ">>>>>Step 277 at [  1.31184380e+02  -8.87510586e-02   1.04631699e+01  -3.12499573e-02]\n",
      "Utilize NN output [[  2.85591800e-02   8.94069672e-08]]\n",
      ">>>>>Step 278 at [  1.31707319e+02  -1.05098194e-01   1.04645974e+01  -3.12499105e-02]\n",
      "Utilize NN output [[  2.74667982e-02   9.92417336e-06]]\n",
      ">>>>>Step 279 at [  1.32230328e+02  -1.21447492e-01   1.04659704e+01  -3.12447179e-02]\n",
      "Utilize NN output [[  2.64172554e-02   1.41561031e-05]]\n",
      ">>>>>Step 280 at [  1.32753404e+02  -1.37796177e-01   1.04672910e+01  -3.12373100e-02]\n",
      "Utilize NN output [[  2.54093483e-02   1.14738941e-05]]\n",
      ">>>>>Step 281 at [  1.33276545e+02  -1.54143011e-01   1.04685612e+01  -3.12313050e-02]\n",
      "Utilize NN output [[  2.44404171e-02   9.20891762e-06]]\n",
      ">>>>>Step 282 at [  1.33799748e+02  -1.70488649e-01   1.04697830e+01  -3.12264848e-02]\n",
      "Utilize NN output [[  2.35104766e-02   1.75833702e-06]]\n",
      ">>>>>Step 283 at [  1.34323011e+02  -1.86833636e-01   1.04709583e+01  -3.12255643e-02]\n",
      "Utilize NN output [[  2.26154774e-02  -4.50015068e-06]]\n",
      ">>>>>Step 284 at [  1.34846332e+02  -2.03179941e-01   1.04720889e+01  -3.12279203e-02]\n",
      "Utilize NN output [[  2.17566956e-02  -1.04606152e-05]]\n",
      ">>>>>Step 285 at [  1.35369709e+02  -2.19529210e-01   1.04731765e+01  -3.12333976e-02]\n",
      "Utilize NN output [[  2.09305361e-02  -1.56462193e-05]]\n",
      ">>>>>Step 286 at [  1.35893138e+02  -2.35883012e-01   1.04742229e+01  -3.12415908e-02]\n",
      "Utilize NN output [[  2.01366488e-02  -1.92224979e-05]]\n",
      ">>>>>Step 287 at [  1.36416619e+02  -2.52242706e-01   1.04752296e+01  -3.12516579e-02]\n",
      "Utilize NN output [[  1.93738695e-02  -2.18451023e-05]]\n",
      ">>>>>Step 288 at [  1.36940149e+02  -2.68609213e-01   1.04761982e+01  -3.12630995e-02]\n",
      "Utilize NN output [[  1.86399929e-02  -2.33948231e-05]]\n",
      ">>>>>Step 289 at [  1.37463726e+02  -2.84983195e-01   1.04771301e+01  -3.12753539e-02]\n",
      "Utilize NN output [[  1.79345701e-02  -2.36928463e-05]]\n",
      ">>>>>Step 290 at [  1.37987349e+02  -3.01365023e-01   1.04780267e+01  -3.12877656e-02]\n",
      "Utilize NN output [[  1.72560662e-02  -2.53021717e-05]]\n",
      ">>>>>Step 291 at [  1.38511015e+02  -3.17754725e-01   1.04788894e+01  -3.13010214e-02]\n",
      "Utilize NN output [[ 0.04312769 -0.00088903]]\n",
      ">>>>>Step 292 at [  1.39034757e+02  -3.34153731e-01   1.04810444e+01  -3.17668252e-02]\n",
      "Utilize NN output [[ 0.04131908 -0.00056419]]\n",
      ">>>>>Step 293 at [  1.39558597e+02  -3.50800046e-01   1.04831092e+01  -3.20624889e-02]\n",
      "Utilize NN output [[ 0.03959734 -0.00033942]]\n",
      ">>>>>Step 294 at [  1.40082532e+02  -3.67604481e-01   1.04850881e+01  -3.22403971e-02]\n",
      "Utilize NN output [[ 0.03798144 -0.00026652]]\n",
      ">>>>>Step 295 at [  1.40606561e+02  -3.84505253e-01   1.04869862e+01  -3.23801225e-02]\n",
      "Utilize NN output [[ 0.03643336 -0.00020084]]\n",
      ">>>>>Step 296 at [  1.41130681e+02  -4.01482255e-01   1.04888071e+01  -3.24854317e-02]\n",
      "Utilize NN output [[ 0.03495206 -0.00014916]]\n"
     ]
    }
   ],
   "source": [
    "N = len(x_nominal)\n",
    "H = 2  # Number of time steps in trajectory.\n",
    "n = 30\n",
    "n_init = 0\n",
    "#n_end = 250\n",
    "n_end = N - H - 1\n",
    "x0 = x_nominal[n_init]  # Initial state.\n",
    "\n",
    "x0s = [[x_nominal[0][0] + 1.0 * (2 * random.random() - 1.0), \\\n",
    "              x_nominal[0][1] + 1.0 * (2 * random.random() - 1.0), \\\n",
    "              x_nominal[0][2] + 1.0 * (2 * random.random() - 1.0), \\\n",
    "              x_nominal[0][3] + 3.0 * (2 * random.random() - 1.0)] for i in range(1)]\n",
    "\n",
    "# Random initial action path.\n",
    "us_init = np.zeros((n - 1, dynamics.action_size))\n",
    "\n",
    "\n",
    "\n",
    "# Instantenous state cost.\n",
    "Q = 0.0 * np.eye(dynamics.state_size)\n",
    "Q[3, 3] = 0.0\n",
    "\n",
    "R = np.eye(dynamics.action_size)\n",
    "R[0, 0] = 0.0\n",
    "R[1, 1] = 0.0\n",
    "\n",
    "\n",
    "q = np.zeros((dynamics.state_size, 1))\n",
    "r = np.zeros((dynamics.action_size, 1)) \n",
    "A = np.array([[[0, 1., 0, 0]], [[0, -1., 0, 0]]])\n",
    "b = np.array([[-0.0], [0.0]])\n",
    "q1 = [150.0, 150.0]\n",
    "q2 = [150.0, 150.0]\n",
    "#A = np.array([[[0, 1, 0, 0]]])\n",
    "#b = np.array([11])\n",
    "\n",
    "def MPSC(agent, x0s):\n",
    "    train_traj = []\n",
    "    nn_traj = []\n",
    "    mpc_traj= []\n",
    "    traj = []\n",
    "    for num in range(len(x0s)):\n",
    "        train_traj.append([])\n",
    "        nn_traj.append([])\n",
    "        mpc_traj.append([])\n",
    "        traj.append([])\n",
    "        x0 = x0s[num]\n",
    "        for step in range(n_init, n_end):\n",
    "            print(\">>>>>Step {} at {}\".format(step, x0))\n",
    "            i = abs(int(x0[0]/0.5))\n",
    "            if i > n_end:\n",
    "                break\n",
    "            x_nominal_ = x_nominal[i: i + H]\n",
    "            x_nn = []\n",
    "            for j in [x0] + x_nominal_[:]:\n",
    "                for k in j:\n",
    "                    x_nn.append(k)\n",
    "            u = agent.run([x_nn])\n",
    "            #print(\"NN outputs control\")\n",
    "            agent_traj[-1] = agent_traj[-1] + [[x0, u[0, :]]]\n",
    "            x1 = dynamics.f(x0, u[0], i)[0]\n",
    "            #print(\"Get next state\")\n",
    "\n",
    "            if i <= n_end - n - 1:\n",
    "                n_ilqr =  n \n",
    "            elif n_end > i:\n",
    "                n_ilqr = n_end - i\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            x0_ = x1[:]\n",
    "            us_ = []\n",
    "            xs_ = []\n",
    "            for _ in range(n_ilqr):\n",
    "                i_ = abs(int(x0_[0]/0.5))\n",
    "                x_nn_ = []\n",
    "                for j in [x0_] + x_nominal[i_ : i_ + H]:\n",
    "                    for k in j:\n",
    "                        x_nn_.append(k)\n",
    "                while len(x_nn_) < 4 *(H + 1):\n",
    "                    for k in x_nominal[-1]:\n",
    "                        x_nn_.append(k)\n",
    "                u_ = agent.run([x_nn_])\n",
    "                xs_.append(x0_[:])\n",
    "                us_.append(u_[0])\n",
    "                x1_ = dynamics.f(x0_, u_[0], i_)[0][:]\n",
    "                x0_ = x1_[:]\n",
    "            xs_ = np.asarray(xs_)\n",
    "            us_init = np.asarray(us_[:-1])\n",
    "            \n",
    "            if (np.squeeze(\\\n",
    "                (xs_ - np.array([[x[0], barrier_u(x[0])[1], 10.0, x[1]] for x in xs_])).dot(A[0].T) - b[0,0]\\\n",
    "                           <= 0)).all() == True and \\\n",
    "                (np.squeeze(\\\n",
    "                (xs_ - np.array([[x[0], barrier_l(x[0])[1], 10.0, x[1]] for x in xs_])).dot(A[1].T) - b[1,0]\\\n",
    "                          <= 0)).all() == True:\n",
    "                traj[-1].append([x0, u[0, :]])\n",
    "                nn_traj[-1].append(traj[-1][-1])\n",
    "                train_traj[-1].append([x_nn, u[0, :]])\n",
    "                print(\"Utilize NN output {}\".format(u))\n",
    "            else: \n",
    "                x_nominal_ilqr = x_nominal[i + 1: i + 1 + n_ilqr]\n",
    "                #us_init = np.random.uniform(-1, 1, (n_ilqr - 1, dynamics.action_size))\n",
    "\n",
    "\n",
    "                cost_ = CarCost(Q = Q, q = q, \\\n",
    "                               R = R, r = r, \\\n",
    "                               A = A, b = b, \\\n",
    "                               q1 = q1, q2 = q2, \\\n",
    "                               x_nominal = x_nominal_ilqr[:], \\\n",
    "                               x_barrier_u = barrier_u,\\\n",
    "                               x_barrier_l = barrier_l)\n",
    "                ilqr_ = iLQR(dynamics, cost_, n_ilqr - 1)\n",
    "                xs, us = ilqr_.fit(x1, us_init, on_iteration=on_iteration)\n",
    "                #print(\"MPC verifying\")\n",
    "\n",
    "\n",
    "                if (np.squeeze(\\\n",
    "                    (xs - np.array([[x[0], barrier_u(x[0])[1], 10.0, x[1]] for x in xs])).dot(A[0].T) - b[0,0]\\\n",
    "                               <= 0)).all() == True and \\\n",
    "                    (np.squeeze(\\\n",
    "                    (xs - np.array([[x[0], barrier_l(x[0])[1], 10.0, x[1]] for x in xs])).dot(A[1].T) - b[1,0]\\\n",
    "                              <= 0)).all() == True:\n",
    "                    traj[-1].append([x0, u[0, :]])\n",
    "                    nn_traj[-1].append(traj[-1][-1])\n",
    "                    train_traj[-1].append([x_nn, u[0, :]])\n",
    "                    print(\"Utilize NN output {}\".format(u))\n",
    "                else:\n",
    "                    max_itr = 5\n",
    "                    while (np.squeeze(\\\n",
    "                    (xs - np.array([[x[0], barrier_u(x[0])[1], 10.0, x[1]] for x in xs])).dot(A[0].T) - b[0,0]\\\n",
    "                               <= 0)).any() == False or \\\n",
    "                    (np.squeeze(\\\n",
    "                    (xs - np.array([[x[0], barrier_l(x[0])[1], 10.0, x[1]] for x in xs])).dot(A[1].T) - b[1,0]\\\n",
    "                              <= 0)).any() == False :\n",
    "                        if max_itr == 0:\n",
    "                            break\n",
    "                        max_itr -= 1    \n",
    "                        cost = CarCost(Q = Q, q = q, \\\n",
    "                               R = R, r = r, \\\n",
    "                               A = A, b = b, \\\n",
    "                               q1 = q1, q2 = q2, \\\n",
    "                               x_nominal = x_nominal_ilqr[:],\\\n",
    "                               x_barrier_u = barrier_u,\\\n",
    "                               x_barrier_l = barrier_l)\n",
    "                        ilqr = iLQR(dynamics, cost, n_ilqr - 1)\n",
    "                        xs, us = ilqr.fit(x0, us_init, on_iteration=on_iteration)\n",
    "                    traj[-1].append([x0, us[0]])\n",
    "                    mpc_traj[-1].append(traj[-1][-1])\n",
    "                    train_traj[-1].append([x_nn, us[0]])\n",
    "                    x1 = dynamics.f(x0, us[0], i)[0]\n",
    "                    print(\"Utilize MPC output {}\".format(us[0]))\n",
    "            x0 = x1[:]\n",
    "            \n",
    "        return  traj, nn_traj, mpc_traj, train_traj\n",
    "    \n",
    "traj, nn_traj, mpc_traj, train_traj = MPSC(agent, x0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79596a0f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_agent_traj(x_nominal, traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f794d367278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_str(nn_traj, mpc_traj):\n",
    "    str_nn = []\n",
    "    posx_nn = []\n",
    "    str_mpc = []\n",
    "    posx_mpc = []\n",
    "    for i in nn_traj[-1]:\n",
    "        posx_nn.append(i[0][0])\n",
    "        str_nn.append(i[1][1])\n",
    "    for j in mpc_traj[-1]:\n",
    "        posx_mpc.append(j[0][0])\n",
    "        str_mpc.append(j[1][1])  \n",
    "\n",
    "    _ = plt.title(\"Actions of the two omnidirectional vehicles\")\n",
    "    _ = plt.scatter(posx_nn, str_nn, s = 0.5, c = \"r\")\n",
    "    _ = plt.scatter(posx_mpc, str_mpc, s = 0.5, c = \"b\")\n",
    "    _ = plt.legend([\"Neural steering\", \"MPC steering\"])\n",
    "\n",
    "draw_str(nn_traj, mpc_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the MPSC guided controller. MPSC solves feasiblity problem to verify the safety of each output of the regression model. Once the output is unsafe, then MPC solves an optimal control and overrides the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red curve in the plot is the trajecotry of the hybrid controller. It can be seen that the vehicle still drive out of the lane boundaries even with the existence of the MPSC. It is because horizon being 30 is too short to predict the unsafe outcome and prevent the vehicle from moving out of the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red dots are the steering commands output by the regression model while the blue dots are from the MPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPSC Guided Learning\n",
    "=====================\n",
    "\n",
    "I have considered two algorithms different from what we have discussed. Instead of filtering the learning-based controller's output during deploying phase, MPC can be used as a filter during training phase. The ultimate goal is that the learning model maintains high performance while avoiding performing unsafe behavior.\n",
    "\n",
    "The basic set up is that the environment has state space $X$, control space $U$ as well as the known, perhaps nonlinear dynamics $x_{k+1} = f(x_k, u_k)$ where $x_k,u_k$ are current state and action pairs and $x_{k+1}$ is next state. Given a learning based controller $g:X\\times \\Theta\\rightarrow U$ where $\\Theta$ is the parameter space, a set of trajectories $\\{\\tau_i|\\tau_i=(x^{(i)}_0, u^{(i)}_0, x^{(i)}_1, u^{(i)}_1, \\ldots)\\}$ can be obtained by executing $g$. Define the convex set of safe states $\\{x|x\\in X, UNSAFE(x)\\leq 0\\}$. Assume that an unsafe controller $g$ is at hand. It can generate at least one trajectory $\\tau=(x_0, a_0, x_1, a_1, \\ldots x_T, a_T\\}$ that reaches an unsafe state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is inspired by the motivation of iLQR, which is to linearize the nonlinear dynamics. Given one trajectory $\\tau$, a perturbation can be added to this trajectory, i.e. $x_k\\rightarrow x_k + \\delta x_k, u_k\\rightarrow u_k +\\delta u_k$. Then the relationship between $\\delta x_k,\\delta u_k$ can be obtained as follows.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "x_{k+1} &=& f(x_k, u_k)\\\\\n",
    "x_{k+1} \\delta x_{k+1} &=& f(x_k+\\delta x_k, u_k + \\delta u_k) \\\\\n",
    "\\delta x_{k+1} &=& f(x_k+\\delta, u_k + \\delta u_k) - f(x_k, u_k)\\\\\n",
    "&\\approx& \\nabla_x f(x_k, u_k) \\delta x_k + \\nabla_u f(x_k, u_k) \\delta u_k\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MPSC Guided Policy Search</h2>\n",
    "\n",
    "Usually, learning-based controller upates its model parameter iteratively during the training phase. We can use MPSC to filter the update. It is already known that $u_k=\\pi(x_k; \\theta)$.Then the following equation holds.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "u_k &=& \\pi(x_k; \\theta)\\\\\n",
    "u_k + \\delta u_k &=& \\pi(x_k + \\delta x_k; \\theta + \\delta \\theta)\\\\\n",
    "\\delta u_k &\\approx& \\nabla_x \\pi(x_k; \\theta) \\delta x_k + \\nabla_\\theta \\pi(x_k; \\theta) \\delta \\theta\n",
    "\\end{eqnarray}\n",
    "\n",
    "Then interpolate it into the linearized dynmics. \n",
    "$$\\delta x_{k+1} \\approx [\\nabla_x f(x_k, u_k)  + \\nabla_u f(x_k, u_k) \\nabla_x \\pi(x_k; \\theta) ]\\delta x_k + \\nabla_u f(x_k, u_k) \\nabla_\\theta \\pi(x_k; \\theta) \\delta \\theta$$\n",
    "\n",
    "\n",
    "At this end, we can determine our MPSC problem as, finding the minimal perturbation on the learning model parameters such that the unsafe trajecotries becomes safe.\n",
    "\n",
    "Previously, we used L-2 norm of the perturbation on the model parameters, i.e. $||\\delta \\theta||^2_2$, to estimate the loss $L(\\delta\\theta)$. The optimization problem is as follows.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\underset{\\delta\\theta}{min}&&||\\delta \\theta||_2^2 \\\\\n",
    "s.t. && \\delta x_{k+1} = [\\nabla_x f(x_k, u_k)  + \\nabla_u f(x_k, u_k) \\nabla_x \\pi(x_k; \\theta) ]\\delta x_k + \\nabla_u f(x_k, u_k) \\nabla_\\theta \\pi(x_k; \\theta) \\delta \\theta\\qquad k=0, 1, 2, \\ldots, T\\\\\n",
    "&& \\delta x_0 = 0\\\\\n",
    "&& UNSAFE(x_k+\\delta x_k)\\leq 0\\qquad k=0, 1, 2, \\ldots, T\n",
    "\\end{eqnarray}\n",
    "\n",
    "It is a typical Quadratic Programming problem especially if the constrains are all convex. But it would be extremely computationally expensive for traditional QP solver because the size of $\\nabla_\\theta \\pi(x; \\theta)$ can be immensively large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the difficulty, we can alternate the problem in the following way.\n",
    "\n",
    "Firstly, given the current model parameter $\\theta_i$, the linearization of the perturbation on the learning model can be rearranged in the following way.\n",
    "\n",
    "$$\\delta \\theta_i^T \\nabla_\\theta \\pi(x_k; \\theta_i) \\approx \\delta u_k^T -\\delta x_k^T \\nabla_x \\pi(x_k; \\theta_i)$$\n",
    "\n",
    "Let the optimal control at state $x_k$ be $u^*_k$, which can be presumably obtained with the initial model parametere $\\theta_0$, i.e. $u^*_k= \\pi(x_k; \\theta_0)$. The loss of the model based on this specific data point can be evaluated by using square error  \n",
    "$$J_{(x_k, u^*_k)}(\\theta_i) = ||\\pi(x_k; \\theta_i) - u^*_k||^2_2$$ \n",
    "or log likelihood with fixed covariance $\\Sigma$\n",
    "$$J_{(x_k, u^*_k)}(\\theta_i) = -log[\\frac{1}{(2\\pi)^{\\frac{n}{2}}\\Sigma} exp\\{-\\frac{1}{2}[\\pi(x_k; \\theta_i) - u^*_k]^T \\Sigma^{-1}[\\pi(x_k,\\theta_i)-u^*_k]\\}$$\n",
    "\n",
    "Either way, up to a scale of constant, $\\nabla_\\theta J_{(x_k, u^*_k)}(\\theta_i)= \\nabla_\\theta \\pi(x_k; \\theta_i)[\\pi(x_k; \\theta_i) - u^*_k]$.\n",
    "\n",
    "Evaluating the loss of the model based on a set $D=\\{\\tau = (x_0, u^*_0, \\ldots, x_k, u^*_k, \\ldots)\\}$ of trajectories sampled from the roll-out of the unchanged model, then the increase on the model's loss due to the perturbation is $J_{D}(\\theta_i+\\delta\\theta_i) - J_{D}(\\theta_i)\\approx \\delta\\theta_i^T \\nabla_\\theta J_{D}(\\theta_i) + \\frac{1}{2}\\delta\\theta_i^T \\nabla^2_\\theta J_{D}(\\theta_i)\\delta\\theta_i$ and it is to be minimized.\n",
    "\n",
    "Using Fisher Information Matrix to replace the second order derivative, the increase of loss turns out to be\n",
    "\\begin{eqnarray}\n",
    "&&\\delta\\theta_i^T \\mathbb{E}_{(x_k, u^*_k)\\sim D}[\\nabla_\\theta J_{(x_k, u^*_k)}(\\theta_i)] + \\frac{1}{2}\\delta\\theta_i^T \\mathbb{E}_{(x_k, u^*_k)\\sim D}[\\nabla_\\theta J_{(x_k, u^*_k)}(\\theta_i) \\nabla_\\theta  J_{(x_k, u^*_k)}(\\theta_i)^T]\\delta\\theta_i\\\\\n",
    "&=&\\mathbb{E}_{(x_k, u^*_k)\\sim D} [\\delta\\theta_i^T\\nabla_\\theta J_{(x_k, u^*_k)}(\\theta_i)] + \\frac{1}{2}\\mathbb{E}_{(x_k, u^*_k)\\sim D}[\\delta\\theta_i^T \\nabla_\\theta J_{(x_k, u^*_k)}(\\theta_i) \\nabla_\\theta  J_{(x_k, u^*_k)}(\\theta_i)^T\\delta\\theta_i]\\\\\n",
    "&=&\\mathbb{E}_{(x_k, u^*_k)\\sim D} \\{\\delta\\theta_i^T\\nabla_\\theta \\pi(x_k; \\theta_i)[\\pi(x_k; \\theta_i) - u^*_k]\\} + \\frac{1}{2}\\mathbb{E}_{(x_k, u^*_k)\\sim D}\\{\\delta\\theta_i^T \\nabla_\\theta \\pi(x_k; \\theta_i)[\\pi(x_k; \\theta_i) - u^*_k] [\\pi(x_k; \\theta_i) - u^*_k]^T\\nabla_\\theta \\pi(x_k; \\theta_i)^T\\delta\\theta_i\\}\\\\\n",
    "&\\approx& \\mathbb{E}_{(x_k, u^*_k)\\sim D}\\{[\\delta u_k -\\delta x_k^T \\nabla_x \\pi(x_k; \\theta_i)][\\pi(x_k; \\theta_i) - u^*_k]\\}+ \\frac{1}{2}\\mathbb{E}_{(x_k, u^*_k)\\sim D}\\{[\\delta u_k^T -\\delta x_k^T \\nabla_x \\pi(x_k; \\theta_i)][\\pi(x_k; \\theta_i) - u^*_k] [\\pi(x_k; \\theta_i) - u^*_k]^T[\\delta u_k^T -\\delta x_k^T \\nabla_x \\pi(x_k; \\theta_i)]^T\\}\\\\\n",
    "&\\approx& \\frac{1}{4|D|} \\sum_{(x_k, u^*_k)\\in D} \\\\\n",
    "&&\\begin{bmatrix} 1\\\\\\delta x_k \\\\ \\delta u_k\\end{bmatrix}^T \n",
    "\\begin{bmatrix} \n",
    "0 &-2[\\pi(x_k; \\theta_i) - u^*_k]^T\\nabla_x \\pi(x_k; \\theta_i)^T &  2[\\pi(x_k; \\theta_i) - u^*_k]^T\\\\ \n",
    "-2\\nabla_x \\pi(x_k; \\theta_i)[\\pi(x_k; \\theta_i) - u^*_k] & \\nabla_x \\pi(x_k; \\theta_i) [\\pi(x_k; \\theta_i) - u^*_k][\\pi(x_k; \\theta_i) - u^*_k]^T \\nabla_x \\pi(x_k; \\theta_i)^T & \\nabla_x \\pi(x_k; \\theta_i) [\\pi(x_k; \\theta_i) - u^*_k][\\pi(x_k; \\theta_i) - u^*_k]^T \\\\\n",
    "2[\\pi(x_k; \\theta_i) - u^*_k] & [\\pi(x_k; \\theta_i) - u^*_k][\\pi(x_k; \\theta_i) - u^*_k]^T \\nabla_x \\pi(x_k; \\theta_i)^T & [\\pi(x_k; \\theta_i) - u^*_k][\\pi(x_k; \\theta_i) - u^*_k]^T \n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}1\\\\\\delta x_k \\\\ \\delta u_k\\end{bmatrix} \n",
    "\\end{eqnarray}\n",
    "\n",
    "As a result, we get a quadratic objective function of which the variables are only $\\delta x$ and $\\delta u$. As $\\pi(,)$ is considered, variable $\\delta\\theta$ is implicit in this objective function. After solving the $\\delta x$ and $\\delta u$, $\\delta\\theta$ can be directly derived and used to modify $\\theta_i$. One thing to be stressed is that $\\pi(x_k;\\theta_i + \\delta\\theta_i)\\neq u_k + \\delta u_k$ because $\\delta u_k$ is induced by both $\\delta x_k$ and $\\delta \\theta_i$.\n",
    "\n",
    "If we choose to directly constrain the trajectory, the $UNSAFE()$ function can be rewritten as a barrier function $b:X\\rightarrow \\mathbb{R}^+$ such that $UNSAFE(x)\\leq \\Rightarrow b(x)\\approx 0$ and $UNSAFE(x)\\geq 0 \\Rightarrow b(x)\\approx \\infty$. One candidate is the exponential. Linearize $b$ in the same way as LQR.\n",
    "\\begin{eqnarray}\n",
    "b(x_k + \\delta x_k) = b(x_k) + \\delta x_k^T \\nabla_x b(x_k) + \\delta x_k^T \\nabla_x b(x_k) \\delta x_k\n",
    "\\end{eqnarray}\n",
    "\n",
    "For instance, $b(x) = w_1 exp[w_2*UNSAFE(x)]$, the barrier can be written as follows. It can be added to the objective. \n",
    "$$b(x_k+\\delta x_k) = b(x_k) + \\delta x_k^T w_1w_2 exp[w_2 UNSAFE(x)]\\nabla_x UNSAFE(x) ^T + \\delta x_k^T \\{w_1 w_2exp[w_2 UNSAFE(x)]\\nabla_{x,x} UNSAFE(x)  + w_1 w_2^2  exp[w_2 UNSAFE(x)]\\nabla_x UNSAFE(x) \\nabla_x UNSAFE(x)^T\\}\\delta_x$$\n",
    "\n",
    "Actually, this constraint will not be needed to be directly enforced in the optimization if the following procedure works.\n",
    "\n",
    "Firstly we need an initially feasible solution $\\delta {\\bf x}$ and $\\delta {\\bf u}$ to ensure the safety of ${\\bf x} + \\delta{\\bf x}$. In fact they can be directly obtained by using MPSC. Once MPSC overrides the learning based controller and invokes a $\\delta u_k=u_k^{safe} - u_k$, a safe trajectory ${\\bf x} + \\delta{\\bf x}$ can be obtained in the end. To get $\\delta {\\bf x}$, the original unsafe trajectory ${\\bf x}$ can be simulated at the very first time when MPSC is involved. From the feasible solution, the first feasible $\\delta \\theta_1$ can be obtained. Henceforth, an iLQR style backward and forward pass can be implemented. \n",
    "\n",
    "It is known that the optimal $\\delta {\\bf u}$ is affine in $\\delta {\\bf x}$, i.e. $\\delta {\\bf u} = k + K \\delta {\\bf x}$. Likewise, $\\delta\\theta^T \\nabla_\\theta \\pi(x;\\theta) = k^T + \\delta {\\bf x}^T [K^T + \\nabla_x \\pi(x; \\theta)]$ in which $k, K$ should be updated via backward pass while $\\delta \\theta$ is updated at the end of the forward pass.  \n",
    "\n",
    "During the forward pass, MPSC should keep monitoring and intervene when necessary. Therefore, the resulted trajectory after a forward pass may not be exctly be induced from the optimal solution. The iteration goes on with safety guarantee and terminates when the changes on $\\delta \\theta$ and $\\delta {\\bf x}$ are trivia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization**\n",
    "\n",
    "1. Learning based controller $\\pi(;\\theta_0)$\n",
    "2. MPSC verifier\n",
    "\n",
    "**Iteration** $i$\n",
    "\n",
    "1. Run $\\pi(;\\theta_i)$ and the safe controller to generate a safe trajectory $\\tau_i$. Train the learning model using $\\tau_i$ with an online scheme to obtain $\\hat{\\theta_i}$ such that all $u$'s in the trajectory equals the outputs of $\\pi(;\\hat{\\theta_i})$ despite some of them are originally generated by the MPSC.\n",
    "2. Run $\\pi(;\\theta_0)$ at every state in the trajectory to obtain $u^*$'s.\n",
    "3. Solve the QP to find $\\delta x$'s and $\\delta u$'s that should be applied to this trajectory. \n",
    "4. Solve $\\delta \\theta_i$ and add to $\\theta_i$ to obtain $\\theta_{i+1}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = []\\nY = []\\nfor i in range(len(train_traj)):\\n    for xy in train_traj[i]:\\n        xy[1][0] /= xy[1][0]\\n        xy[1][1] /= xy[1][1]\\n        X.append(xy[0][:])\\n        Y.append(xy[1][:])\\n\\nagent_.data_process(X = X, Y = Y)\\nagent_.train(num_epoch = 10)\\n'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n = 2\n",
    "agent_ = NeuralNetwork(input_size = (n + 1) * 4, model_name = 'mlp_temp_H2', batch_size = 1, checkpoint = 'checkpoints/mlp_temp_H2_765.pt')\n",
    "\n",
    "\"\"\"\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(len(train_traj)):\n",
    "    for xy in train_traj[i]:\n",
    "        xy[1][0] /= xy[1][0]\n",
    "        xy[1][1] /= xy[1][1]\n",
    "        X.append(xy[0][:])\n",
    "        Y.append(xy[1][:])\n",
    "\n",
    "agent_.data_process(X = X, Y = Y)\n",
    "agent_.train(num_epoch = 10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>Step 0 at [-0.07109108273090925, 0.38115485845135, 9.286429500835544, -0.64671899713711445]\n",
      "Utilize NN output [[ 0.99728394  0.99922329]]\n",
      ">>>>>Step 1 at [ 0.30022631  0.10079533  9.32445206 -0.29324603]\n",
      "Utilize NN output [[ 0.99603748  0.998101  ]]\n",
      ">>>>>Step 2 at [ 0.74745551 -0.03424612  9.36244831  0.06145402]\n",
      "Utilize NN output [[ 0.99526298  0.99546504]]\n",
      ">>>>>Step 3 at [  1.21564195e+00  -5.43790392e-03   9.40042818e+00   4.17078660e-01]\n",
      "Utilize NN output [[ 0.99391454  0.98716182]]\n",
      ">>>>>Step 4 at [ 1.64623882  0.18534801  9.43837951  0.77248512]\n",
      "Utilize NN output [[ 0.9914512   0.95788032]]\n",
      ">>>>>Step 5 at [ 1.98489559  0.51536963  9.47627853  1.1232766 ]\n",
      "Utilize NN output [[ 0.98206687  0.74212861]]\n",
      ">>>>>Step 6 at [ 2.19033732  0.9433735   9.51397649  1.42198287]\n",
      "Utilize NN output [[ 0.98310995  0.57343042]]\n",
      ">>>>>Step 7 at [ 2.26100653  1.41474735  9.55169695  1.66833499]\n",
      "iteration 0 accepted [  6.77707260e+30] [ 2.12931597  2.36158962  9.53940296  1.65029575] [ -4.45965576e+03  -2.10323721e-01]\n",
      "Utilize MPC output [ -4.45965576e+03  -2.10323721e-01]\n",
      ">>>>>Step 8 at [ 2.2146191   1.88881812  9.50169695  1.56934296]\n",
      "iteration 0 accepted [  1.38437483e+62] [ 2.1876882   2.83976053  9.48937515  1.52744957] [ -5.27104590e+03  -2.15983257e-01]\n",
      "iteration 0 accepted [  7.95579707e+30] [ 2.21530776  2.36265246  9.45169695  1.46829891] [ -4.37961963e+03  -2.15983257e-01]\n",
      "Utilize MPC output [ -4.37961963e+03  -2.15983257e-01]\n",
      ">>>>>Step 9 at [ 2.21530776  2.36265246  9.45169695  1.46829891]\n",
      "iteration 0 accepted [  4.41821015e+92] [ 2.29330434  3.30598701  9.4393414   1.40522126] [ -6.11913623e+03  -2.20810741e-01]\n",
      "iteration 0 accepted [  3.99485270e+61] [ 2.26353381  2.83151362  9.40169695  1.36561064] [ -5.25961035e+03  -2.20810741e-01]\n",
      "iteration 0 accepted [  3.99485270e+61] [ 2.26353381  2.83151362  9.40169695  1.36561064] [ -5.25961035e+03  -2.20810741e-01]\n",
      "iteration 0 accepted [  3.99485270e+61] [ 2.26353381  2.83151362  9.40169695  1.36561064] [ -5.25961035e+03  -2.20810741e-01]\n",
      "iteration 0 accepted [  3.99485270e+61] [ 2.26353381  2.83151362  9.40169695  1.36561064] [ -5.25961035e+03  -2.20810741e-01]\n",
      "iteration 0 accepted [  3.99485270e+61] [ 2.26353381  2.83151362  9.40169695  1.36561064] [ -5.25961035e+03  -2.20810741e-01]\n",
      "Utilize MPC output [ -5.25961035e+03  -2.20810741e-01]\n",
      ">>>>>Step 10 at [ 2.26353381  2.83151362  9.40169695  1.36561064]\n",
      "iteration 0 accepted [  1.09029630e+122] [ 2.44536969  3.75547536  9.38930234  1.28327761] [ -7.03167383e+03  -2.24202365e-01]\n",
      "iteration 0 accepted [  4.29726695e+91] [ 2.35905842  3.2905138   9.35169695  1.26194764] [ -6.18865332e+03  -2.24202365e-01]\n",
      "iteration 0 accepted [  4.29726695e+91] [ 2.35905842  3.2905138   9.35169695  1.26194764] [ -6.18865332e+03  -2.24202365e-01]\n",
      "iteration 0 accepted [  4.29726695e+91] [ 2.35905842  3.2905138   9.35169695  1.26194764] [ -6.18865332e+03  -2.24202365e-01]\n",
      "iteration 0 accepted [  4.29726695e+91] [ 2.35905842  3.2905138   9.35169695  1.26194764] [ -6.18865332e+03  -2.24202365e-01]\n",
      "iteration 0 accepted [  4.29726695e+91] [ 2.35905842  3.2905138   9.35169695  1.26194764] [ -6.18865332e+03  -2.24202365e-01]\n",
      "Utilize MPC output [ -6.18865332e+03  -2.24202365e-01]\n",
      ">>>>>Step 11 at [ 2.35905842  3.2905138   9.35169695  1.26194764]\n",
      "iteration 0 accepted [  1.06086706e+150] [ 2.64144824  4.18366869  9.33925748  1.22411335] [ -8.08906055e+03  -9.20267701e-02]\n",
      "iteration 0 accepted [  4.83958348e+120] [ 2.5008065   3.73478362  9.30169695  1.21903838] [ -7.23415381e+03  -9.20267701e-02]\n",
      "iteration 0 accepted [  4.83958348e+120] [ 2.5008065   3.73478362  9.30169695  1.21903838] [ -7.23415381e+03  -9.20267701e-02]\n",
      "iteration 0 accepted [  4.83958348e+120] [ 2.5008065   3.73478362  9.30169695  1.21903838] [ -7.23415381e+03  -9.20267701e-02]\n",
      "iteration 0 accepted [  4.83958348e+120] [ 2.5008065   3.73478362  9.30169695  1.21903838] [ -7.23415381e+03  -9.20267701e-02]\n",
      "iteration 0 accepted [  4.83958348e+120] [ 2.5008065   3.73478362  9.30169695  1.21903838] [ -7.23415381e+03  -9.20267701e-02]\n",
      "Utilize MPC output [ -7.23415381e+03  -9.20267701e-02]\n",
      ">>>>>Step 12 at [ 2.5008065   3.73478362  9.30169695  1.21903838]\n",
      "iteration 0 accepted [  7.76459909e+177] [ 2.82009054  4.6101093   9.28931086  1.12100476] [ -9.02706738e+03  -2.22062960e-01]\n",
      "iteration 0 accepted [  1.40144853e+149] [ 2.66062016  4.17021715  9.25169695  1.11742505] [ -8.17851855e+03  -2.22062960e-01]\n",
      "iteration 0 accepted [  1.40144853e+149] [ 2.66062016  4.17021715  9.25169695  1.11742505] [ -8.17851855e+03  -2.22062960e-01]\n",
      "iteration 0 accepted [  1.40144853e+149] [ 2.66062016  4.17021715  9.25169695  1.11742505] [ -8.17851855e+03  -2.22062960e-01]\n",
      "iteration 0 accepted [  1.40144853e+149] [ 2.66062016  4.17021715  9.25169695  1.11742505] [ -8.17851855e+03  -2.22062960e-01]\n",
      "iteration 0 accepted [  1.40144853e+149] [ 2.66062016  4.17021715  9.25169695  1.11742505] [ -8.17851855e+03  -2.22062960e-01]\n",
      "Utilize MPC output [ -8.17851855e+03  -2.22062960e-01]\n",
      ">>>>>Step 13 at [ 2.66062016  4.17021715  9.25169695  1.11742505]\n",
      "iteration 0 accepted [  2.71845173e+203] [ 3.07096524  5.00114111  9.23926631  1.00533674] [ -1.02579814e+04  -2.21908569e-01]\n",
      "iteration 0 accepted [  1.76248135e+176] [ 2.86268423  4.58494592  9.20169695  1.01642594] [ -9.35567773e+03  -2.21908569e-01]\n",
      "iteration 0 accepted [  1.76248135e+176] [ 2.86268423  4.58494592  9.20169695  1.01642594] [ -9.35567773e+03  -2.21908569e-01]\n",
      "iteration 0 accepted [  1.76248135e+176] [ 2.86268423  4.58494592  9.20169695  1.01642594] [ -9.35567773e+03  -2.21908569e-01]\n",
      "iteration 0 accepted [  1.76248135e+176] [ 2.86268423  4.58494592  9.20169695  1.01642594] [ -9.35567773e+03  -2.21908569e-01]\n",
      "iteration 0 accepted [  1.76248135e+176] [ 2.86268423  4.58494592  9.20169695  1.01642594] [ -9.35567773e+03  -2.21908569e-01]\n",
      "Utilize MPC output [ -9.35567773e+03  -2.21908569e-01]\n",
      ">>>>>Step 14 at [ 2.86268423  4.58494592  9.20169695  1.01642594]\n",
      "iteration 0 accepted [  1.16187887e+227] [ 3.35683153  5.36295578  9.18921784  0.955991  ] [ -1.17697578e+04  -8.12424421e-02]\n",
      "iteration 0 accepted [  5.38126911e+201] [ 3.10421861  4.97506201  9.15169695  0.97912954] [ -1.07609932e+04  -8.12424421e-02]\n",
      "iteration 0 accepted [  5.38126911e+201] [ 3.10421861  4.97506201  9.15169695  0.97912954] [ -1.07609932e+04  -8.12424421e-02]\n",
      "iteration 0 accepted [  5.38126911e+201] [ 3.10421861  4.97506201  9.15169695  0.97912954] [ -1.07609932e+04  -8.12424421e-02]\n",
      "iteration 0 accepted [  5.38126911e+201] [ 3.10421861  4.97506201  9.15169695  0.97912954] [ -1.07609932e+04  -8.12424421e-02]\n",
      "iteration 0 accepted [  5.38126911e+201] [ 3.10421861  4.97506201  9.15169695  0.97912954] [ -1.07609932e+04  -8.12424421e-02]\n",
      "Utilize MPC output [ -1.07609932e+04  -8.12424421e-02]\n",
      ">>>>>Step 15 at [ 3.10421861  4.97506201  9.15169695  0.97912954]\n",
      "iteration 0 accepted [  1.28133653e+251] [ 3.62257     5.73113575  9.13927528  0.86622404] [ -1.28306289e+04  -2.08113626e-01]\n",
      "iteration 0 accepted [  2.94371656e+226] [ 3.3587372   5.35382549  9.10169695  0.88525133] [ -1.18344238e+04  -2.08113626e-01]\n",
      "iteration 0 accepted [  2.94371656e+226] [ 3.3587372   5.35382549  9.10169695  0.88525133] [ -1.18344238e+04  -2.08113626e-01]\n",
      "iteration 0 accepted [  2.94371656e+226] [ 3.3587372   5.35382549  9.10169695  0.88525133] [ -1.18344238e+04  -2.08113626e-01]\n",
      "iteration 0 accepted [  2.94371656e+226] [ 3.3587372   5.35382549  9.10169695  0.88525133] [ -1.18344238e+04  -2.08113626e-01]\n",
      "iteration 0 accepted [  2.94371656e+226] [ 3.3587372   5.35382549  9.10169695  0.88525133] [ -1.18344238e+04  -2.08113626e-01]\n",
      "Utilize MPC output [ -1.18344238e+04  -2.08113626e-01]\n",
      ">>>>>Step 16 at [ 3.3587372   5.35382549  9.10169695  0.88525133]\n",
      "iteration 0 accepted [  9.78390172e+271] [ 3.9461597   6.05097427  9.08922856  0.82513519] [ -1.47405996e+04  -6.75553009e-02]\n",
      "iteration 0 accepted [  2.56695644e+249] [ 3.64605776  5.70512731  9.05169695  0.85455462] [ -1.35599053e+04  -6.75553009e-02]\n",
      "iteration 0 accepted [  2.56695644e+249] [ 3.64605776  5.70512731  9.05169695  0.85455462] [ -1.35599053e+04  -6.75553009e-02]\n",
      "iteration 0 accepted [  2.56695644e+249] [ 3.64605776  5.70512731  9.05169695  0.85455462] [ -1.35599053e+04  -6.75553009e-02]\n",
      "iteration 0 accepted [  2.56695644e+249] [ 3.64605776  5.70512731  9.05169695  0.85455462] [ -1.35599053e+04  -6.75553009e-02]\n",
      "iteration 0 accepted [  2.56695644e+249] [ 3.64605776  5.70512731  9.05169695  0.85455462] [ -1.35599053e+04  -6.75553009e-02]\n",
      "Utilize MPC output [ -1.35599053e+04  -6.75553009e-02]\n",
      ">>>>>Step 17 at [ 3.64605776  5.70512731  9.05169695  0.85455462]\n",
      "iteration 0 accepted [  4.17200379e+293] [ 4.24898292  6.38229272  9.0392862   0.74595453] [ -1.58453848e+04  -1.91866219e-01]\n",
      "iteration 0 accepted [  4.33504821e+271] [ 3.94238369  6.04555951  9.00169695  0.76876897] [ -1.47128477e+04  -1.91866219e-01]\n",
      "iteration 0 accepted"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/lib/python3/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/depend/workspace/MPSC_Guided_Imitation_Learning/ilqr/ilqr/controller.py:161: UserWarning: Singular matrix\n",
      "  warnings.warn(str(e))\n",
      "/home/depend/workspace/MPSC_Guided_Imitation_Learning/ilqr/ilqr/controller.py:168: UserWarning: exceeded max regularization term\n",
      "  warnings.warn(\"exceeded max regularization term\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [  4.33504821e+271] [ 3.94238369  6.04555951  9.00169695  0.76876897] [ -1.47128477e+04  -1.91866219e-01]\n",
      "iteration 0 accepted [  4.33504821e+271] [ 3.94238369  6.04555951  9.00169695  0.76876897] [ -1.47128477e+04  -1.91866219e-01]\n",
      "iteration 0 accepted [  4.33504821e+271] [ 3.94238369  6.04555951  9.00169695  0.76876897] [ -1.47128477e+04  -1.91866219e-01]\n",
      "iteration 0 accepted [  4.33504821e+271] [ 3.94238369  6.04555951  9.00169695  0.76876897] [ -1.47128477e+04  -1.91866219e-01]\n",
      "Utilize MPC output [ -1.47128477e+04  -1.91866219e-01]\n",
      ">>>>>Step 18 at [ 3.94238369  6.04555951  9.00169695  0.76876897]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-57d4dc31d0f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_traj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpc_traj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_traj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMPSC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdraw_agent_traj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_nominal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdraw_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_traj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpc_traj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-151-11bfeff0f474>\u001b[0m in \u001b[0;36mMPSC\u001b[0;34m(agent, x0s)\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mcost_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCarCost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mq1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mx_nominal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_nominal_ilqr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mx_barrier_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbarrier_u\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0mx_barrier_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbarrier_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0milqr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miLQR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ilqr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0milqr_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mus_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;31m#print(\"MPC verifying\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/depend/workspace/MPSC_Guided_Imitation_Learning/ilqr/ilqr/controller.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x0, us_init, n_iterations, tol, on_iteration)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mxs_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mus_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                     \u001b[0mJ_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trajectory_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mus_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mJ_new\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mJ_opt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/depend/workspace/MPSC_Guided_Imitation_Learning/ilqr/ilqr/controller.py\u001b[0m in \u001b[0;36m_trajectory_cost\u001b[0;34m(self, xs, us)\u001b[0m\n\u001b[1;32m    223\u001b[0m         J = map(lambda args: self.cost.l(*args), zip(xs[:-1], us,\n\u001b[1;32m    224\u001b[0m                                                      range(self.N)))\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/depend/workspace/MPSC_Guided_Imitation_Learning/ilqr/ilqr/examples/car.py\u001b[0m in \u001b[0;36ml\u001b[0;34m(self, x, u, i, terminal)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_barrier_l\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mx_barrier_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_barrier_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mx_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "traj, nn_traj, mpc_traj, train_traj = MPSC(agent_, x0s)\n",
    "draw_agent_traj(x_nominal, traj)\n",
    "draw_str(nn_traj, mpc_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "from cvxopt import spmatrix, spdiag, matrix, solvers, sparse\n",
    "\n",
    "n = 5\n",
    "checkpoint = 'checkpoints/mlp_H5_995.pt'\n",
    "epoch_init = 0\n",
    "num_epoch = 500\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "def numpy_sparse_to_spmatrix(X):\n",
    "    X = coo_matrix(X)\n",
    "    coo = X.tocoo()\n",
    "    SP = spmatrix(coo.data.tolist(), coo.row.tolist(), coo.col.tolist(), size = coo.shape)\n",
    "    return SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27416\n"
     ]
    }
   ],
   "source": [
    "agent = NeuralNetwork(input_size = (n + 1) * 4, \\\n",
    "                      model_name = 'mlp_H10_MPSC_', \\\n",
    "                      batch_size = 1000, \\\n",
    "                      checkpoint = checkpoint)\n",
    "\n",
    "agent.data_process(paths = ['expert_traj/expert_pts_10058_H10.p', 'expert_traj/expert_pts_17358_H10.p'])\n",
    "\n",
    "if checkpoint is not None:\n",
    "    checkpoint = torch.load(checkpoint, map_location=device)\n",
    "    agent.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    agent.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch_init = checkpoint['epoch'] + 1\n",
    "    loss = checkpoint['loss']\n",
    "    agent.model.eval()\n",
    "    loss.backward()\n",
    "    agent.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1001] avg_loss: 0.770\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44418, 44418) (44418, 1) (1160, 44418) (1160, 1) (2328, 44418) (2328, 1)\n",
      "Starting solving QP\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  2.2868e+00 -2.9075e+03  3e+04  7e-01  2e-10\n",
      " 1:  2.4048e+00 -1.3293e+03  8e+03  2e-01  2e-10\n",
      " 2:  1.3179e+01 -9.4909e+02  5e+03  1e-01  8e-10\n",
      " 3:  2.8352e+01 -6.7030e+02  4e+03  6e-02  9e-10\n",
      " 4:  6.0571e+01 -2.0510e+02  1e+03  2e-02  9e-10\n",
      " 5:  7.5835e+01  5.6768e+00  1e+02  1e-03  4e-10\n",
      " 6:  7.5477e+01  6.5513e+01  2e+01  2e-04  1e-10\n",
      " 7:  7.4688e+01  7.2191e+01  5e+00  4e-05  9e-11\n",
      " 8:  7.4429e+01  7.3777e+01  1e+00  7e-06  5e-11\n",
      " 9:  7.4380e+01  7.4143e+01  4e-01  2e-06  3e-11\n",
      "10:  7.4362e+01  7.4294e+01  1e-01  5e-07  1e-11\n",
      "11:  7.4357e+01  7.4343e+01  2e-02  7e-08  6e-12\n",
      "12:  7.4356e+01  7.4351e+01  8e-03  2e-08  3e-12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ac50cab30847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting solving QP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0msol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolvers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;31m#sol = {'x': [0.0 for i in range(dynamics.state_size * (N - n + 1) + agent.num_parameters(agent.model))]}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mdelta_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv_py3/lib/python3.5/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mqp\u001b[0;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[1;32m   4483\u001b[0m             'residual as dual infeasibility certificate': dinfres}\n\u001b[1;32m   4484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4485\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconeqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkktsolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/virtualenv_py3/lib/python3.5/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[0;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[1;32m   2254\u001b[0m         \u001b[0;31m# On exit, they contain ux, uy, uz.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miters\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv_py3/lib/python3.5/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mkktsolver\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m   1979\u001b[0m              \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkkt_chol2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m          \u001b[0;32mdef\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1981\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxnewcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxnewcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv_py3/lib/python3.5/site-packages/cvxopt/misc.py\u001b[0m in \u001b[0;36mfactor\u001b[0;34m(W, H, Df)\u001b[0m\n\u001b[1;32m   1456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'singular'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m                 base.syrk(A, F['S'], trans = 'T', beta = 1.0, partial = \n\u001b[0;32m-> 1458\u001b[0;31m                     True) \n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m                 \u001b[0mlapack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x00 = [[x_path[0][0] + 1.0 * (2 * random.random() - 1.0), \\\n",
    "              x_path[0][1] + 3.0 * (2 * random.random() - 1.0), \\\n",
    "              x_path[0][2] + 1.0 * (2 * random.random() - 1.0), \\\n",
    "              x_path[0][3] + 3.0 * (2 * random.random() - 1.0)]]  # Initial state.\n",
    "\n",
    "for epoch in range(epoch_init, num_epoch + epoch_init):  # loop over the dataset multiple times\n",
    "    dataloader = data_utils.DataLoader(agent.dataset, batch_size = agent.batch_size, shuffle = True)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.float().to(agent.device), labels.float().to(agent.device)\n",
    "        inputs.requires_grad = True\n",
    "        \n",
    "        agent.optimizer.zero_grad()\n",
    "        \n",
    "        outputs = agent.model(inputs)\n",
    "        outputs = torch.reshape(outputs, (outputs.size()[0], agent.output_size))\n",
    "        \n",
    "        loss = agent.criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        # print statistics\n",
    "\n",
    "  \n",
    "        running_loss += loss.item()\n",
    "        agent.optimizer.step()\n",
    "        #agent.run()\n",
    "           \n",
    "            \n",
    "    if epoch % 5 == 0:\n",
    "        print('[Epoch %d] avg_loss: %.3f' % (epoch + 1, running_loss/len(dataloader)))\n",
    "        torch.save({'epoch': epoch, \\\n",
    "                    'model_state_dict': agent.model.state_dict(), \\\n",
    "                    'optimizer_state_dict': agent.optimizer.state_dict(), \\\n",
    "                    'loss': loss}, str('checkpoints/' + str(agent.model_name) + '_' + str(epoch) + '.pt'))\n",
    "        x0 = x00\n",
    "\n",
    "        N = 300\n",
    "        n = 10\n",
    "        agent_traj = []\n",
    "        \n",
    "        f_x = np.empty((N -n + 1, dynamics.state_size, dynamics.state_size))\n",
    "        f_u = np.empty((N -n + 1, dynamics.state_size, dynamics.action_size))\n",
    "        g_x = np.empty((N -n + 1, dynamics.action_size, dynamics.state_size, ))\n",
    "        g_theta = np.empty((N -n + 1, dynamics.action_size, agent.num_parameters(agent.model)))\n",
    "        '''\n",
    "        print(f_x.shape)\n",
    "        print(f_u.shape)\n",
    "        print(g_x.shape)\n",
    "        print(g_theta.shape)\n",
    "        '''\n",
    "        \n",
    "        F_x = np.empty((N - n + 1, dynamics.state_size, dynamics.state_size))\n",
    "        F_theta = np.empty((N - n + 1, dynamics.state_size, agent.num_parameters(agent.model)))\n",
    "        \n",
    "        # Search every time step\n",
    "        for i in range(int(N - n) + 1):\n",
    "            # Generate (state, control) pairs\n",
    "            x = []\n",
    "            for j in x0[0]:\n",
    "                x.append(j)\n",
    "            for j in range(len(x_path[i: i + n])):\n",
    "                for k in range(len(x_path[j + i])):\n",
    "                    x.append(x_path[j + i][k])\n",
    "            x = np.asarray([x])\n",
    "            x = torch.tensor(x, requires_grad = True).float().to(agent.device)\n",
    "            \n",
    "            agent.optimizer.zero_grad()\n",
    "            u = agent.model(x)\n",
    "            \n",
    "            \n",
    "            for j in range(dynamics.action_size):\n",
    "                # Get gradient w.r.t input x[0:4] <<<< g_x\n",
    "                g_x[i, j, :] = torch.autograd.grad(u[0, j], x, retain_graph = True\\\n",
    "                                                  )[0].cpu().numpy()[0, 0:dynamics.state_size]\n",
    "                \n",
    "                # Get gradient w.r.t model parameters theta <<<< g_theta\n",
    "                torch.autograd.backward(u[0, j], retain_graph = True)\n",
    "                k = 0\n",
    "                for theta in agent.model.parameters():\n",
    "                    g_theta_ = theta.grad.data.flatten() \n",
    "                    g_theta[i, j, k : k + g_theta_.size()[0]] = g_theta_.cpu().numpy()\n",
    "                    k += g_theta_.size()[0]\n",
    "            \n",
    "            \n",
    "            x = x.detach().cpu().numpy()\n",
    "            u = u.detach().cpu().numpy()\n",
    "            \n",
    "            # Get dynamics w.r.t x <<<< f_x         \n",
    "            f_x[i] = dynamics.f_x(x[0, 0:4], u[0], i)\n",
    "            \n",
    "            # Get dynamics w.r.t u <<<< f_u\n",
    "            f_u[i] = dynamics.f_u(x[0, 0:4], u[0], i)\n",
    "            \n",
    "            # Record the trajectory\n",
    "            agent_traj[-1].append([x[0], u[0]])\n",
    "                              \n",
    "            # Find next state\n",
    "            x0 = dynamics.f(x[0, 0:4], u[0], i)\n",
    "            \n",
    "            # Calculate f_x + f_u g_x\n",
    "            F_x[i] = f_x[i] + f_u[i].dot(g_x[i])\n",
    "            # Calculate f_u g_theta\n",
    "            F_theta[i] = f_u[i].dot(g_theta[i])\n",
    "        \n",
    "        draw_agent_traj(x_path, [agent_traj])\n",
    "        \n",
    "        # Define QP objective Q, p\n",
    "        Q = np.eye(dynamics.state_size * (N - n + 1) + agent.num_parameters(agent.model))\n",
    "        q = np.zeros((dynamics.state_size * (N - n + 1) + agent.num_parameters(agent.model), 1))\n",
    "        \n",
    "        # Define QP constraint Ax = b, Gx <= h\n",
    "        A = np.zeros((dynamics.state_size * (N - n), \\\n",
    "                      dynamics.state_size * (N - n + 1) \\\n",
    "                      + agent.num_parameters(agent.model)))\n",
    "        \n",
    "        b = np.zeros((dynamics.state_size * (N - n), 1))\n",
    "        G = np.zeros((2 * dynamics.state_size * (N - n + 1), \\\n",
    "                      dynamics.state_size * (N - n + 1)\\\n",
    "                      + agent.num_parameters(agent.model)))\n",
    "        h = np.zeros((2 * dynamics.state_size * (N - n + 1), 1))\n",
    "        \n",
    "        for i in range(0, N - n + 1):\n",
    "            x = agent_traj[i][0]\n",
    "            u = agent_traj[i][1]\n",
    "            \n",
    "            if i <= N - n - 1:\n",
    "                A[dynamics.state_size * i : dynamics.state_size * (i + 1), \\\n",
    "                  dynamics.state_size * i : dynamics.state_size * (i + 1)] = F_x[i, :]\n",
    "                A[dynamics.state_size * i : dynamics.state_size * (i + 1), \\\n",
    "                  dynamics.state_size * (i + 1) : dynamics.state_size * (i + 2)] = - np.eye(dynamics.state_size)\n",
    "                A[dynamics.state_size * i : dynamics.state_size * (i + 1),\\\n",
    "                  -agent.num_parameters(agent.model) : ] = F_theta[i, :]\n",
    "                \n",
    "            G[dynamics.state_size * 2 * i + 1, dynamics.state_size * i + 1] = 1.0\n",
    "            G[dynamics.state_size * (2 * i + 1) + 1, dynamics.state_size * i + 1] =  - 1.0\n",
    "            \n",
    "            if i != 0:\n",
    "                h[dynamics.state_size * 2 * i + 1] = nominal(x[0])[0] - x[1]\n",
    "                h[dynamics.state_size * (2 * i + 1) + 1] = x[1] - nominal(x[0])[1]\n",
    "        \n",
    "            for j in range(dynamics.state_size):\n",
    "                Q[i * dynamics.state_size + j] = 0.0\n",
    "        \n",
    "        \n",
    "        print(Q.shape, q.shape, A.shape, b.shape, G.shape, h.shape)\n",
    "        \n",
    "        Q = numpy_sparse_to_spmatrix(Q)\n",
    "        q = matrix(q)\n",
    "        A = numpy_sparse_to_spmatrix(A)\n",
    "        b = matrix(b)\n",
    "        G = numpy_sparse_to_spmatrix(G)\n",
    "        h = matrix(h)\n",
    "        print(\"Starting solving QP\")\n",
    "        sol=solvers.qp(Q, q, G, h, A, b)\n",
    "        #sol = {'x': [0.0 for i in range(dynamics.state_size * (N - n + 1) + agent.num_parameters(agent.model))]}\n",
    "        delta_theta = list(sol['x'])\n",
    "\n",
    "        pickle.dump(delta_theta, open('model_parameter_perturbation_' + str(i) + '.p', 'wb'))\n",
    "        print('QP solved')\n",
    "        print('Model prameter updated')\n",
    "        \n",
    "        i = dynamics.state_size * (N - n + 1)\n",
    "        for theta in agent.model.parameters():\n",
    "            theta.data += torch.FloatTensor(delta_theta[i: i + theta.data.numel()]).reshape(theta.data.size()).to(agent.device)\n",
    "            i += theta.data.numel()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
