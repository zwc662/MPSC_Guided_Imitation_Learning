{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPSC Guided Learning\n",
    "=====================\n",
    "\n",
    "The basic set up is that the environment has state space $X$, control space $U$ as well as the known, perhaps nonlinear dynamics $x_{k+1} = f(x_k, u_k)$ where $x_k,u_k$ are current state and action pairs and $x_{k+1}$ is the next state. Given a learning based controller $\\pi:X\\times \\Theta\\rightarrow U$ where $\\Theta$ is the parameter space, a set of trajectories $\\{\\tau_i|\\tau_i=(x^{(i)}_0, u^{(i)}_0, x^{(i)}_1, u^{(i)}_1, \\ldots)\\}$ can be obtained from the roll-out of $\\pi$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is inspired by how LQR linearizes the nonlinear dynamics. Given one trajectory $\\tau$, a perturbation can be added to this trajectory, i.e. $x_k\\rightarrow x_k + \\delta x_k, u_k\\rightarrow u_k +\\delta u_k$. Then the relationship between $\\delta x_k,\\delta u_k$ can be obtained as follows.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "x_{k+1} &=& f(x_k, u_k)\\\\\n",
    "x_{k+1} + \\delta x_{k+1} &=& f(x_k+\\delta x_k, u_k + \\delta u_k) \\\\\n",
    "\\delta x_{k+1} &=& f(x_k+\\delta, u_k + \\delta u_k) - f(x_k, u_k)\\\\\n",
    "&\\approx& \\nabla_x f(x_k, u_k) \\delta x_k + \\nabla_u f(x_k, u_k) \\delta u_k\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MPSC Guided Policy Search</h2>\n",
    "\n",
    "It is already known that $u_k=\\pi(x_k; \\theta_i)$ under current model parameter $\\theta_i$. Likewise, it can linearized around specific point.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "u_k &=& \\pi(x_k; \\theta_i)\\\\\n",
    "u_k + \\delta u_k &=& \\pi(x_k + \\delta x_k; \\theta_i + \\delta \\theta_i)\\\\\n",
    "\\delta u_k &\\approx& \\nabla_x \\pi(x_k; \\theta_i) \\delta x_k + \\nabla_\\theta \\pi(x_k; \\theta_i) \\delta \\theta_i\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the computational difficulty of our previous QP formulation, we can alternate the problem in the following way.\n",
    "\n",
    "Firstly, the linearization of the perturbation on the learning model can be rearranged in the following way.\n",
    "\n",
    "$$\\delta \\theta_i^T \\nabla_\\theta \\pi(x_k; \\theta_i) \\approx \\delta u_k -\\delta x_k^T \\nabla_x \\pi(x_k; \\theta_i)$$\n",
    "\n",
    "Let the optimal control at state $x_k$ be $u^*_k$, which can be presumably obtained with the initial(right after training) model parameter $\\theta^*$, i.e. $u^*_k= \\pi(x_k; \\theta^*)$. The loss of the model based on this specific data point can be evaluated by using square error  \n",
    "$$J_{(x_k, u^*_k)}(\\theta_i) = ||\\pi(x_k; \\theta_i) - u^*_k||^2_2$$ \n",
    "or log likelihood with fixed covariance $\\Sigma$\n",
    "$$J_{(x_k, u^*_k)}(\\theta_i) = -log[\\frac{1}{(2\\pi)^{\\frac{n}{2}}\\Sigma} exp\\{-\\frac{1}{2}[\\pi(x_k; \\theta_i) - u^*_k]^T \\Sigma^{-1}[\\pi(x_k,\\theta_i)-u^*_k]\\}$$\n",
    "\n",
    "Either way, up to a scale of constant, $\\nabla_\\theta J_{(x_k, u^*_k)}(\\theta_i)= \\nabla_\\theta \\pi(x_k; \\theta_i)[\\pi(x_k; \\theta_i) - u^*_k]$.\n",
    "\n",
    "Evaluating the loss of the model based on a dataset $D=\\{(x_k, u^*_k)\\}$, the increase on the model's loss due to a perturbation $\\delta \\theta_i$ on the model parameter is $J_{D}(\\theta_i+\\delta\\theta_i) - J_{D}(\\theta_i)\\approx \\delta\\theta_i^T \\nabla_\\theta J_{D}(\\theta_i) + \\frac{1}{2}\\delta\\theta_i^T \\nabla^2_\\theta J_{D}(\\theta_i)\\delta\\theta_i$.\n",
    "\n",
    "Using Fisher Information Matrix to replace the second order derivative, the increase of loss turns out to be\n",
    "\\begin{eqnarray}\n",
    "&&\\delta\\theta_i^T \\mathbb{E}_{(x_k, u^*_k)\\sim D}[\\nabla_\\theta J_{(x_k, u^*_k)}(\\theta_i)] + \\frac{1}{2}\\delta\\theta_i^T \\mathbb{E}_{(x_k, u^*_k)\\sim D}[\\nabla_\\theta J_{(x_k, u^*_k)}(\\theta_i) \\nabla_\\theta  J_{(x_k, u^*_k)}(\\theta_i)^T]\\delta\\theta_i\\\\\n",
    "&=&\\mathbb{E}_{(x_k, u^*_k)\\sim D} [\\delta\\theta_i^T\\nabla_\\theta J_{(x_k, u^*_k)}(\\theta_i)] + \\frac{1}{2}\\mathbb{E}_{(x_k, u^*_k)\\sim D}[\\delta\\theta_i^T \\nabla_\\theta J_{(x_k, u^*_k)}(\\theta_i) \\nabla_\\theta  J_{(x_k, u^*_k)}(\\theta_i)^T\\delta\\theta_i]\\\\\n",
    "&=&\\mathbb{E}_{(x_k, u^*_k)\\sim D} \\{\\delta\\theta_i^T\\nabla_\\theta \\pi(x_k; \\theta_i)[\\pi(x_k; \\theta_i) - u^*_k]\\} + \\frac{1}{2}\\mathbb{E}_{(x_k, u^*_k)\\sim D}\\{\\delta\\theta_i^T \\nabla_\\theta \\pi(x_k; \\theta_i)[\\pi(x_k; \\theta_i) - u^*_k] [\\pi(x_k; \\theta_i) - u^*_k]^T\\nabla_\\theta \\pi(x_k; \\theta_i)^T\\delta\\theta_i\\}\\\\\n",
    "&\\approx& \\mathbb{E}_{(x_k, u^*_k)\\sim D}\\{[\\delta u_k -\\delta x_k^T \\nabla_x \\pi(x_k; \\theta_i)][\\pi(x_k; \\theta_i) - u^*_k]\\}+ \\frac{1}{2}\\mathbb{E}_{(x_k, u^*_k)\\sim D}\\{[\\delta u_k -\\delta x_k^T \\nabla_x \\pi(x_k; \\theta_i)][\\pi(x_k; \\theta_i) - u^*_k] [\\pi(x_k; \\theta_i) - u^*_k]^T[\\delta u_k -\\delta x_k^T \\nabla_x \\pi(x_k; \\theta_i)]^T\\}\n",
    "\\end{eqnarray}\n",
    "\n",
    "As a result, we get a quadratic objective function of which the variables are only $\\delta x$ and $\\delta u$. As $\\pi(,)$ is considered, variable $\\delta\\theta$ is implicit. After solving the $\\delta x$ and $\\delta u$, $\\delta\\theta$ can be directly derived and used to modify $\\theta_i$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
